{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e66518e-71cb-4c3d-bccf-f85f17d8b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import  glob\n",
    "import time\n",
    "import albumentations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from utils.utils import segment_cell\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder# creating instance of one-hot-encoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "### Internal Imports\n",
    "from models.ResNext50 import Myresnext50\n",
    "from train.train_classification import trainer_classification\n",
    "from utils.utils import configure_optimizers\n",
    "from Datasets.DataLoader import Img_DataLoader\n",
    "\n",
    "### PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe32bca7-aab5-41df-afd9-98727f30a1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (16591, 4)          Training set label count: {'Other': 9474, 'Myeloid': 6158, 'Lymphoid': 959} \n",
      "\n",
      "Validation set shape: (2074, 4)         Validation set label count: {'Other': 1185, 'Myeloid': 770, 'Lymphoid': 119} \n",
      "\n",
      "Test set shape: (2074, 4)         Validation set label count: {'Other': 1184, 'Myeloid': 770, 'Lymphoid': 120} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data, split it into training and validation dataframes\n",
    "df = pd.read_pickle('notextimagepaths.pkl')\n",
    " \n",
    "train_df, val_df = train_test_split(df, test_size=0.20, random_state=42, stratify=df['Label'])\n",
    "val_df, test_df = train_test_split(val_df, test_size=0.5, random_state=42, stratify=val_df['Label'])\n",
    "print(f\"Training set shape: {train_df.shape}          Training set label count: {str(Counter(train_df['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "print(f\"Validation set shape: {val_df.shape}         Validation set label count: {str(Counter(val_df['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "print(f\"Test set shape: {test_df.shape}         Validation set label count: {str(Counter(test_df['Label'].to_list()))[7:][1:][:-1]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037f2d57-2fd0-4995-8f5f-72f4e3d87295",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Code used to store each image with removed text in a separate folder, such that it doesnt have to be done during training thus saving much time\n",
    "# df = pd.read_pickle('imagepaths.pkl')\n",
    "\n",
    "# def remove_text(filepath):\n",
    "\n",
    "#     # Load image\n",
    "#     img = cv2.imread(filepath)\n",
    "#     img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     # Step 1: Copy the image\n",
    "#     img_segmented = img_rgb.copy()\n",
    "    \n",
    "#     # Step 2: Define region to black out (bottom-right corner)\n",
    "#     height, width, _ = img_segmented.shape\n",
    "#     corner_hmin = int(height * 0.15)  # bottom 10%\n",
    "#     corner_hmax = int(height * 0.05)  # bottom 5%\n",
    "#     corner_w = int(width * 0.42)   # rightmost 25%\n",
    "    \n",
    "#     # Step 3: Black out that region\n",
    "#     img_segmented[height - corner_hmin : height - corner_hmax, 0 : corner_w] = 0  # set to black\n",
    "        \n",
    "#     return img_rgb, img_segmented\n",
    "\n",
    "# filepaths = df['Filepath'].tolist()\n",
    "\n",
    "# for filepath in filepaths:\n",
    "#     filename =  filepath.split('\\\\')[-1]\n",
    "#     orig_img, seg_img = remove_text(filepath)\n",
    "#     img_bgr = cv2.cvtColor(seg_img, cv2.COLOR_RGB2BGR)\n",
    "#     cv2.imwrite(os.path.join('Datasets/notextimages', filename), img_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49be3e84-3648-41d0-bd09-3ec7f9e0f754",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For testing purposes to check whether a model trained on no data indeed performs poorly, thus ensuring that there is no label leakage during evaluation\n",
    "\n",
    "# train_df_w, train_df_small = train_test_split(train_df, test_size=0.003, random_state=42, stratify=train_df['Label'])\n",
    "# val_df_w, val_df_small = train_test_split(val_df, test_size=0.05, random_state=42, stratify=val_df['Label'])\n",
    "# test_df_w, test_df_small = train_test_split(test_df, test_size=0.05, random_state=42, stratify=test_df['Label'])\n",
    "\n",
    "# print(f\"Training set shape: {train_df_small.shape}          Training set label count: {str(Counter(train_df_small['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "# print(f\"Validation set shape: {val_df_small.shape}         Validation set label count: {str(Counter(val_df_small['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "# print(f\"Test set shape: {test_df_small.shape}         Validation set label count: {str(Counter(test_df_small['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "\n",
    "# # Load df that represents the one hot encoding of each cell type (Myeloid, Lymphoid, other)\n",
    "# cell_types_df = pd.read_pickle(\"cell_types_df.pkl\")\n",
    "\n",
    "# # Load model\n",
    "# resnext50_pretrained = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\n",
    "# my_extended_model = Myresnext50(my_pretrained_model= resnext50_pretrained, num_classes = 3)\n",
    "\n",
    "# X_train_small = train_df_small['Filepath'].to_list()\n",
    "# X_val_small = val_df_small['Filepath'].to_list()\n",
    "\n",
    "# # Load labels\n",
    "# train_labels_small = train_df_small['Label'].to_list()\n",
    "# validation_labels_small = val_df_small['Label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba1fe00a-3ec1-4575-b1d1-6e81abc5f2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\moone/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\moone\\miniconda3\\envs\\thesis\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\moone\\miniconda3\\envs\\thesis\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load filepaths\n",
    "X_train = train_df['Filepath'].to_list()\n",
    "X_val = val_df['Filepath'].to_list()\n",
    "\n",
    "# Load labels\n",
    "train_labels = train_df['Label'].to_list()\n",
    "validation_labels = val_df['Label'].to_list()\n",
    "\n",
    "# Load df that represents the one hot encoding of each cell type (Myeloid, Lymphoid, other)\n",
    "cell_types_df = pd.read_pickle(\"cell_types_df.pkl\")\n",
    "\n",
    "# Load model\n",
    "resnext50_pretrained = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\n",
    "my_extended_model = Myresnext50(my_pretrained_model= resnext50_pretrained, num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a3ea6b-a52c-4ac3-bd4d-de5aeab45789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple augumentation to improve the data generalibility\n",
    "\n",
    "transform_pipeline = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e317cbab-fa58-4e9e-ab1b-4d9ce018e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training setup\n",
    "trainer = trainer_classification(train_image_files=X_train, validation_image_files=X_val, train_labels=train_labels, validation_labels=validation_labels, model=my_extended_model,\n",
    "                                     img_transform=transform_pipeline, init_lr=0.001,\n",
    "                                     lr_decay_every_x_epochs=10,\n",
    "\n",
    "                                     weight_decay=0.0005, batch_size=32, epochs=30, gamma=0.1, df=cell_types_df,\n",
    "                                     save_checkpoints_dir='checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e3c9e8-3c3a-41f4-bcf1-ee89be97997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes\n",
    "\n",
    "# dataset = Img_DataLoader(img_list=X_train, labels=train_labels, split='train', transform = transform_pipeline, df = cell_types_df)\n",
    "# shuffle = True\n",
    "# dataloader = DataLoader(dataset, batch_size=32, num_workers=2, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39a05e49-861e-4464-b168-f9823ac383c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Create model\n",
      "==> List learnable parameters\n",
      "==> Load data\n",
      "16591\n",
      "2074\n",
      "==> Configure optimizer\n",
      "10\n",
      "==> Start training\n",
      "==> Create the saving dictionary\n",
      "The directory exists, overrode duplicate files\n",
      "==> Epoch: 1 Step: 400 LR: 0.001000 Total Loss: 0.2995 Runtime: 4.82 s/50 iters.\n",
      "==> Epoch: 1 Step: 450 LR: 0.001000 Total Loss: 0.5055 Runtime: 5.91 s/50 iters.\n",
      "==> Epoch: 1 Step: 500 LR: 0.001000 Total Loss: 0.4243 Runtime: 6.03 s/50 iters.\n",
      "==> Epoch: 1 Step: 550 LR: 0.001000 Total Loss: 0.3183 Runtime: 6.03 s/50 iters.\n",
      "==> Epoch: 1 Step: 600 LR: 0.001000 Total Loss: 0.1842 Runtime: 5.66 s/50 iters.\n",
      "==> Epoch: 1 Step: 650 LR: 0.001000 Total Loss: 0.2823 Runtime: 6.14 s/50 iters.\n",
      "==> Epoch: 1 Step: 700 LR: 0.001000 Total Loss: 0.2615 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 1 Step: 750 LR: 0.001000 Total Loss: 0.1495 Runtime: 6.00 s/50 iters.\n",
      "==> Epoch: 1 Step: 800 LR: 0.001000 Total Loss: 0.4136 Runtime: 6.17 s/50 iters.\n",
      "==> Epoch: 1 Step: 850 LR: 0.001000 Total Loss: 0.3049 Runtime: 5.96 s/50 iters.\n",
      "==> Epoch: 1 Loss 0.347350 .\n",
      "==> Epoch: 2 Step: 900 LR: 0.000976 Total Loss: 0.3449 Runtime: 2.62 s/50 iters.\n",
      "==> Epoch: 2 Step: 950 LR: 0.000976 Total Loss: 0.3605 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 2 Step: 1000 LR: 0.000976 Total Loss: 0.1738 Runtime: 6.10 s/50 iters.\n",
      "==> Epoch: 2 Step: 1050 LR: 0.000976 Total Loss: 0.4869 Runtime: 6.34 s/50 iters.\n",
      "==> Epoch: 2 Step: 1100 LR: 0.000976 Total Loss: 0.2191 Runtime: 6.27 s/50 iters.\n",
      "==> Epoch: 2 Step: 1150 LR: 0.000976 Total Loss: 0.3730 Runtime: 6.31 s/50 iters.\n",
      "==> Epoch: 2 Step: 1200 LR: 0.000976 Total Loss: 0.2926 Runtime: 6.25 s/50 iters.\n",
      "==> Epoch: 2 Step: 1250 LR: 0.000976 Total Loss: 0.4919 Runtime: 6.38 s/50 iters.\n",
      "==> Epoch: 2 Step: 1300 LR: 0.000976 Total Loss: 0.2875 Runtime: 6.14 s/50 iters.\n",
      "==> Epoch: 2 Step: 1350 LR: 0.000976 Total Loss: 0.3430 Runtime: 6.34 s/50 iters.\n",
      "==> Epoch: 2 Step: 1400 LR: 0.000976 Total Loss: 0.2261 Runtime: 6.22 s/50 iters.\n",
      "==> Epoch: 2 Loss 0.615429 .\n",
      "==> Epoch: 3 Step: 1450 LR: 0.000905 Total Loss: 0.2507 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 3 Step: 1500 LR: 0.000905 Total Loss: 0.3176 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 3 Step: 1550 LR: 0.000905 Total Loss: 0.2342 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 3 Step: 1600 LR: 0.000905 Total Loss: 0.3131 Runtime: 6.63 s/50 iters.\n",
      "==> Epoch: 3 Step: 1650 LR: 0.000905 Total Loss: 0.1700 Runtime: 6.70 s/50 iters.\n",
      "==> Epoch: 3 Step: 1700 LR: 0.000905 Total Loss: 0.3748 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 3 Step: 1750 LR: 0.000905 Total Loss: 0.2558 Runtime: 6.66 s/50 iters.\n",
      "==> Epoch: 3 Step: 1800 LR: 0.000905 Total Loss: 0.2066 Runtime: 6.62 s/50 iters.\n",
      "==> Epoch: 3 Step: 1850 LR: 0.000905 Total Loss: 0.1656 Runtime: 6.97 s/50 iters.\n",
      "==> Epoch: 3 Step: 1900 LR: 0.000905 Total Loss: 0.1129 Runtime: 7.08 s/50 iters.\n",
      "==> Epoch: 3 Loss 1.542597 .\n",
      "==> Epoch: 4 Step: 1950 LR: 0.000794 Total Loss: 0.1292 Runtime: 4.41 s/50 iters.\n",
      "==> Epoch: 4 Step: 2000 LR: 0.000794 Total Loss: 0.3416 Runtime: 6.87 s/50 iters.\n",
      "==> Epoch: 4 Step: 2050 LR: 0.000794 Total Loss: 0.3471 Runtime: 6.78 s/50 iters.\n",
      "==> Epoch: 4 Step: 2100 LR: 0.000794 Total Loss: 0.2805 Runtime: 6.46 s/50 iters.\n",
      "==> Epoch: 4 Step: 2150 LR: 0.000794 Total Loss: 0.2007 Runtime: 6.69 s/50 iters.\n",
      "==> Epoch: 4 Step: 2200 LR: 0.000794 Total Loss: 0.1009 Runtime: 6.66 s/50 iters.\n",
      "==> Epoch: 4 Step: 2250 LR: 0.000794 Total Loss: 0.1667 Runtime: 6.75 s/50 iters.\n",
      "==> Epoch: 4 Step: 2300 LR: 0.000794 Total Loss: 0.2195 Runtime: 6.82 s/50 iters.\n",
      "==> Epoch: 4 Step: 2350 LR: 0.000794 Total Loss: 0.2607 Runtime: 6.62 s/50 iters.\n",
      "==> Epoch: 4 Step: 2400 LR: 0.000794 Total Loss: 0.2857 Runtime: 6.52 s/50 iters.\n",
      "==> Epoch: 4 Loss 0.347947 .\n",
      "==> Epoch: 5 Step: 2450 LR: 0.000655 Total Loss: 0.3743 Runtime: 1.67 s/50 iters.\n",
      "==> Epoch: 5 Step: 2500 LR: 0.000655 Total Loss: 0.5019 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 5 Step: 2550 LR: 0.000655 Total Loss: 0.2169 Runtime: 6.49 s/50 iters.\n",
      "==> Epoch: 5 Step: 2600 LR: 0.000655 Total Loss: 0.1417 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 5 Step: 2650 LR: 0.000655 Total Loss: 0.2483 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 5 Step: 2700 LR: 0.000655 Total Loss: 0.2559 Runtime: 6.86 s/50 iters.\n",
      "==> Epoch: 5 Step: 2750 LR: 0.000655 Total Loss: 0.3789 Runtime: 7.11 s/50 iters.\n",
      "==> Epoch: 5 Step: 2800 LR: 0.000655 Total Loss: 0.1244 Runtime: 7.04 s/50 iters.\n",
      "==> Epoch: 5 Step: 2850 LR: 0.000655 Total Loss: 0.1346 Runtime: 7.06 s/50 iters.\n",
      "==> Epoch: 5 Step: 2900 LR: 0.000655 Total Loss: 0.3434 Runtime: 7.05 s/50 iters.\n",
      "==> Epoch: 5 Step: 2950 LR: 0.000655 Total Loss: 0.1908 Runtime: 7.00 s/50 iters.\n",
      "==> Epoch: 5 Loss 0.230852 .\n",
      "==> Epoch: 6 Step: 3000 LR: 0.000500 Total Loss: 0.2004 Runtime: 6.10 s/50 iters.\n",
      "==> Epoch: 6 Step: 3050 LR: 0.000500 Total Loss: 0.2416 Runtime: 6.85 s/50 iters.\n",
      "==> Epoch: 6 Step: 3100 LR: 0.000500 Total Loss: 0.1075 Runtime: 7.08 s/50 iters.\n",
      "==> Epoch: 6 Step: 3150 LR: 0.000500 Total Loss: 0.1602 Runtime: 7.09 s/50 iters.\n",
      "==> Epoch: 6 Step: 3200 LR: 0.000500 Total Loss: 0.4824 Runtime: 7.14 s/50 iters.\n",
      "==> Epoch: 6 Step: 3250 LR: 0.000500 Total Loss: 0.0947 Runtime: 7.11 s/50 iters.\n",
      "==> Epoch: 6 Step: 3300 LR: 0.000500 Total Loss: 0.2185 Runtime: 7.03 s/50 iters.\n",
      "==> Epoch: 6 Step: 3350 LR: 0.000500 Total Loss: 0.0659 Runtime: 7.03 s/50 iters.\n",
      "==> Epoch: 6 Step: 3400 LR: 0.000500 Total Loss: 0.3022 Runtime: 7.03 s/50 iters.\n",
      "==> Epoch: 6 Step: 3450 LR: 0.000500 Total Loss: 0.1602 Runtime: 7.02 s/50 iters.\n",
      "==> Epoch: 6 Loss 0.287436 .\n",
      "==> Epoch: 7 Step: 3500 LR: 0.000345 Total Loss: 0.3546 Runtime: 3.41 s/50 iters.\n",
      "==> Epoch: 7 Step: 3550 LR: 0.000345 Total Loss: 0.2588 Runtime: 6.81 s/50 iters.\n",
      "==> Epoch: 7 Step: 3600 LR: 0.000345 Total Loss: 0.0796 Runtime: 6.98 s/50 iters.\n",
      "==> Epoch: 7 Step: 3650 LR: 0.000345 Total Loss: 0.0540 Runtime: 7.00 s/50 iters.\n",
      "==> Epoch: 7 Step: 3700 LR: 0.000345 Total Loss: 0.1519 Runtime: 7.07 s/50 iters.\n",
      "==> Epoch: 7 Step: 3750 LR: 0.000345 Total Loss: 0.1942 Runtime: 7.06 s/50 iters.\n",
      "==> Epoch: 7 Step: 3800 LR: 0.000345 Total Loss: 0.2235 Runtime: 7.03 s/50 iters.\n",
      "==> Epoch: 7 Step: 3850 LR: 0.000345 Total Loss: 0.1932 Runtime: 7.01 s/50 iters.\n",
      "==> Epoch: 7 Step: 3900 LR: 0.000345 Total Loss: 0.2446 Runtime: 7.01 s/50 iters.\n",
      "==> Epoch: 7 Step: 3950 LR: 0.000345 Total Loss: 0.0625 Runtime: 7.03 s/50 iters.\n",
      "==> Epoch: 7 Loss 0.200132 .\n",
      "==> Epoch: 8 Step: 4000 LR: 0.000206 Total Loss: 0.0626 Runtime: 0.73 s/50 iters.\n",
      "==> Epoch: 8 Step: 4050 LR: 0.000206 Total Loss: 0.1744 Runtime: 6.79 s/50 iters.\n",
      "==> Epoch: 8 Step: 4100 LR: 0.000206 Total Loss: 0.0868 Runtime: 6.89 s/50 iters.\n",
      "==> Epoch: 8 Step: 4150 LR: 0.000206 Total Loss: 0.3424 Runtime: 7.03 s/50 iters.\n",
      "==> Epoch: 8 Step: 4200 LR: 0.000206 Total Loss: 0.0492 Runtime: 7.11 s/50 iters.\n",
      "==> Epoch: 8 Step: 4250 LR: 0.000206 Total Loss: 0.4290 Runtime: 7.09 s/50 iters.\n",
      "==> Epoch: 8 Step: 4300 LR: 0.000206 Total Loss: 0.1946 Runtime: 7.08 s/50 iters.\n",
      "==> Epoch: 8 Step: 4350 LR: 0.000206 Total Loss: 0.0445 Runtime: 5.68 s/50 iters.\n",
      "==> Epoch: 8 Step: 4400 LR: 0.000206 Total Loss: 0.2155 Runtime: 4.94 s/50 iters.\n",
      "==> Epoch: 8 Step: 4450 LR: 0.000206 Total Loss: 0.0647 Runtime: 5.32 s/50 iters.\n",
      "==> Epoch: 8 Step: 4500 LR: 0.000206 Total Loss: 0.1754 Runtime: 4.63 s/50 iters.\n",
      "==> Epoch: 8 Loss 0.285674 .\n",
      "==> Epoch: 9 Step: 4550 LR: 0.000095 Total Loss: 0.0908 Runtime: 5.13 s/50 iters.\n",
      "==> Epoch: 9 Step: 4600 LR: 0.000095 Total Loss: 0.0873 Runtime: 6.91 s/50 iters.\n",
      "==> Epoch: 9 Step: 4650 LR: 0.000095 Total Loss: 0.0636 Runtime: 7.16 s/50 iters.\n",
      "==> Epoch: 9 Step: 4700 LR: 0.000095 Total Loss: 0.0653 Runtime: 7.07 s/50 iters.\n",
      "==> Epoch: 9 Step: 4750 LR: 0.000095 Total Loss: 0.1116 Runtime: 7.09 s/50 iters.\n",
      "==> Epoch: 9 Step: 4800 LR: 0.000095 Total Loss: 0.1009 Runtime: 7.09 s/50 iters.\n",
      "==> Epoch: 9 Step: 4850 LR: 0.000095 Total Loss: 0.0457 Runtime: 7.15 s/50 iters.\n",
      "==> Epoch: 9 Step: 4900 LR: 0.000095 Total Loss: 0.1437 Runtime: 7.08 s/50 iters.\n",
      "==> Epoch: 9 Step: 4950 LR: 0.000095 Total Loss: 0.0716 Runtime: 7.09 s/50 iters.\n",
      "==> Epoch: 9 Step: 5000 LR: 0.000095 Total Loss: 0.2560 Runtime: 7.08 s/50 iters.\n",
      "==> Epoch: 9 Loss 0.180304 .\n",
      "==> Epoch: 10 Step: 5050 LR: 0.000024 Total Loss: 0.0601 Runtime: 2.50 s/50 iters.\n",
      "==> Epoch: 10 Step: 5100 LR: 0.000024 Total Loss: 0.1023 Runtime: 6.87 s/50 iters.\n",
      "==> Epoch: 10 Step: 5150 LR: 0.000024 Total Loss: 0.0100 Runtime: 7.13 s/50 iters.\n",
      "==> Epoch: 10 Step: 5200 LR: 0.000024 Total Loss: 0.1757 Runtime: 7.08 s/50 iters.\n",
      "==> Epoch: 10 Step: 5250 LR: 0.000024 Total Loss: 0.0791 Runtime: 7.25 s/50 iters.\n",
      "==> Epoch: 10 Step: 5300 LR: 0.000024 Total Loss: 0.0573 Runtime: 7.19 s/50 iters.\n",
      "==> Epoch: 10 Step: 5350 LR: 0.000024 Total Loss: 0.1005 Runtime: 7.21 s/50 iters.\n",
      "==> Epoch: 10 Step: 5400 LR: 0.000024 Total Loss: 0.0293 Runtime: 7.13 s/50 iters.\n",
      "==> Epoch: 10 Step: 5450 LR: 0.000024 Total Loss: 0.0594 Runtime: 7.06 s/50 iters.\n",
      "==> Epoch: 10 Step: 5500 LR: 0.000024 Total Loss: 0.1139 Runtime: 7.09 s/50 iters.\n",
      "==> Epoch: 10 Step: 5550 LR: 0.000024 Total Loss: 0.0962 Runtime: 7.57 s/50 iters.\n",
      "==> Epoch: 10 Loss 0.182669 .\n",
      "==> Epoch: 11 Step: 5600 LR: 0.000000 Total Loss: 0.0528 Runtime: 6.72 s/50 iters.\n",
      "==> Epoch: 11 Step: 5650 LR: 0.000000 Total Loss: 0.0586 Runtime: 6.96 s/50 iters.\n",
      "==> Epoch: 11 Step: 5700 LR: 0.000000 Total Loss: 0.0473 Runtime: 6.45 s/50 iters.\n",
      "==> Epoch: 11 Step: 5750 LR: 0.000000 Total Loss: 0.0168 Runtime: 6.36 s/50 iters.\n",
      "==> Epoch: 11 Step: 5800 LR: 0.000000 Total Loss: 0.0094 Runtime: 6.96 s/50 iters.\n",
      "==> Epoch: 11 Step: 5850 LR: 0.000000 Total Loss: 0.1610 Runtime: 7.38 s/50 iters.\n",
      "==> Epoch: 11 Step: 5900 LR: 0.000000 Total Loss: 0.0815 Runtime: 7.10 s/50 iters.\n",
      "==> Epoch: 11 Step: 5950 LR: 0.000000 Total Loss: 0.0853 Runtime: 7.27 s/50 iters.\n",
      "==> Epoch: 11 Step: 6000 LR: 0.000000 Total Loss: 0.2058 Runtime: 7.07 s/50 iters.\n",
      "==> Epoch: 11 Step: 6050 LR: 0.000000 Total Loss: 0.1311 Runtime: 7.11 s/50 iters.\n",
      "==> Epoch: 11 Loss 0.183416 .\n",
      "==> Epoch: 12 Step: 6100 LR: 0.000024 Total Loss: 0.0342 Runtime: 4.20 s/50 iters.\n",
      "==> Epoch: 12 Step: 6150 LR: 0.000024 Total Loss: 0.1347 Runtime: 6.89 s/50 iters.\n",
      "==> Epoch: 12 Step: 6200 LR: 0.000024 Total Loss: 0.0248 Runtime: 7.17 s/50 iters.\n",
      "==> Epoch: 12 Step: 6250 LR: 0.000024 Total Loss: 0.0144 Runtime: 6.39 s/50 iters.\n",
      "==> Epoch: 12 Step: 6300 LR: 0.000024 Total Loss: 0.1022 Runtime: 6.48 s/50 iters.\n",
      "==> Epoch: 12 Step: 6350 LR: 0.000024 Total Loss: 0.1018 Runtime: 7.01 s/50 iters.\n",
      "==> Epoch: 12 Step: 6400 LR: 0.000024 Total Loss: 0.0044 Runtime: 6.59 s/50 iters.\n",
      "==> Epoch: 12 Step: 6450 LR: 0.000024 Total Loss: 0.0431 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 12 Step: 6500 LR: 0.000024 Total Loss: 0.0572 Runtime: 8.27 s/50 iters.\n",
      "==> Epoch: 12 Step: 6550 LR: 0.000024 Total Loss: 0.0109 Runtime: 7.35 s/50 iters.\n",
      "==> Epoch: 12 Loss 0.188198 .\n",
      "==> Epoch: 13 Step: 6600 LR: 0.000095 Total Loss: 0.1336 Runtime: 1.57 s/50 iters.\n",
      "==> Epoch: 13 Step: 6650 LR: 0.000095 Total Loss: 0.1293 Runtime: 7.13 s/50 iters.\n",
      "==> Epoch: 13 Step: 6700 LR: 0.000095 Total Loss: 0.1611 Runtime: 6.75 s/50 iters.\n",
      "==> Epoch: 13 Step: 6750 LR: 0.000095 Total Loss: 0.0560 Runtime: 6.21 s/50 iters.\n",
      "==> Epoch: 13 Step: 6800 LR: 0.000095 Total Loss: 0.0444 Runtime: 6.42 s/50 iters.\n",
      "==> Epoch: 13 Step: 6850 LR: 0.000095 Total Loss: 0.0722 Runtime: 6.49 s/50 iters.\n",
      "==> Epoch: 13 Step: 6900 LR: 0.000095 Total Loss: 0.2430 Runtime: 7.81 s/50 iters.\n",
      "==> Epoch: 13 Step: 6950 LR: 0.000095 Total Loss: 0.1262 Runtime: 7.68 s/50 iters.\n",
      "==> Epoch: 13 Step: 7000 LR: 0.000095 Total Loss: 0.0132 Runtime: 7.64 s/50 iters.\n",
      "==> Epoch: 13 Step: 7050 LR: 0.000095 Total Loss: 0.1308 Runtime: 7.58 s/50 iters.\n",
      "==> Epoch: 13 Step: 7100 LR: 0.000095 Total Loss: 0.1104 Runtime: 7.46 s/50 iters.\n",
      "==> Epoch: 13 Loss 0.211532 .\n",
      "==> Epoch: 14 Step: 7150 LR: 0.000206 Total Loss: 0.0118 Runtime: 6.18 s/50 iters.\n",
      "==> Epoch: 14 Step: 7200 LR: 0.000206 Total Loss: 0.0140 Runtime: 7.39 s/50 iters.\n",
      "==> Epoch: 14 Step: 7250 LR: 0.000206 Total Loss: 0.1691 Runtime: 7.54 s/50 iters.\n",
      "==> Epoch: 14 Step: 7300 LR: 0.000206 Total Loss: 0.1021 Runtime: 7.58 s/50 iters.\n",
      "==> Epoch: 14 Step: 7350 LR: 0.000206 Total Loss: 0.1477 Runtime: 6.20 s/50 iters.\n",
      "==> Epoch: 14 Step: 7400 LR: 0.000206 Total Loss: 0.1975 Runtime: 6.72 s/50 iters.\n",
      "==> Epoch: 14 Step: 7450 LR: 0.000206 Total Loss: 0.0386 Runtime: 6.74 s/50 iters.\n",
      "==> Epoch: 14 Step: 7500 LR: 0.000206 Total Loss: 0.1569 Runtime: 6.25 s/50 iters.\n",
      "==> Epoch: 14 Step: 7550 LR: 0.000206 Total Loss: 0.0991 Runtime: 6.09 s/50 iters.\n",
      "==> Epoch: 14 Step: 7600 LR: 0.000206 Total Loss: 0.2909 Runtime: 6.13 s/50 iters.\n",
      "==> Epoch: 14 Loss 0.187606 .\n",
      "==> Epoch: 15 Step: 7650 LR: 0.000345 Total Loss: 0.0527 Runtime: 2.90 s/50 iters.\n",
      "==> Epoch: 15 Step: 7700 LR: 0.000345 Total Loss: 0.1141 Runtime: 5.99 s/50 iters.\n",
      "==> Epoch: 15 Step: 7750 LR: 0.000345 Total Loss: 0.0668 Runtime: 6.12 s/50 iters.\n",
      "==> Epoch: 15 Step: 7800 LR: 0.000345 Total Loss: 0.4070 Runtime: 7.51 s/50 iters.\n",
      "==> Epoch: 15 Step: 7850 LR: 0.000345 Total Loss: 0.0724 Runtime: 6.34 s/50 iters.\n",
      "==> Epoch: 15 Step: 7900 LR: 0.000345 Total Loss: 0.1277 Runtime: 6.26 s/50 iters.\n",
      "==> Epoch: 15 Step: 7950 LR: 0.000345 Total Loss: 0.1200 Runtime: 6.24 s/50 iters.\n",
      "==> Epoch: 15 Step: 8000 LR: 0.000345 Total Loss: 0.0653 Runtime: 6.24 s/50 iters.\n",
      "==> Epoch: 15 Step: 8050 LR: 0.000345 Total Loss: 0.1717 Runtime: 6.26 s/50 iters.\n",
      "==> Epoch: 15 Step: 8100 LR: 0.000345 Total Loss: 0.1623 Runtime: 6.23 s/50 iters.\n",
      "==> Epoch: 15 Loss 0.188917 .\n",
      "==> Epoch: 16 Step: 8150 LR: 0.000500 Total Loss: 0.0312 Runtime: 0.49 s/50 iters.\n",
      "==> Epoch: 16 Step: 8200 LR: 0.000500 Total Loss: 0.2147 Runtime: 6.45 s/50 iters.\n",
      "==> Epoch: 16 Step: 8250 LR: 0.000500 Total Loss: 0.1938 Runtime: 6.49 s/50 iters.\n",
      "==> Epoch: 16 Step: 8300 LR: 0.000500 Total Loss: 0.0582 Runtime: 6.35 s/50 iters.\n",
      "==> Epoch: 16 Step: 8350 LR: 0.000500 Total Loss: 0.0680 Runtime: 6.37 s/50 iters.\n",
      "==> Epoch: 16 Step: 8400 LR: 0.000500 Total Loss: 0.0309 Runtime: 6.25 s/50 iters.\n",
      "==> Epoch: 16 Step: 8450 LR: 0.000500 Total Loss: 0.0380 Runtime: 6.22 s/50 iters.\n",
      "==> Epoch: 16 Step: 8500 LR: 0.000500 Total Loss: 0.1965 Runtime: 6.34 s/50 iters.\n",
      "==> Epoch: 16 Step: 8550 LR: 0.000500 Total Loss: 0.2080 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 16 Step: 8600 LR: 0.000500 Total Loss: 0.0342 Runtime: 6.68 s/50 iters.\n",
      "==> Epoch: 16 Step: 8650 LR: 0.000500 Total Loss: 0.2423 Runtime: 6.62 s/50 iters.\n",
      "==> Epoch: 16 Loss 0.214470 .\n",
      "==> Epoch: 17 Step: 8700 LR: 0.000655 Total Loss: 0.0774 Runtime: 4.91 s/50 iters.\n",
      "==> Epoch: 17 Step: 8750 LR: 0.000655 Total Loss: 0.0637 Runtime: 6.83 s/50 iters.\n",
      "==> Epoch: 17 Step: 8800 LR: 0.000655 Total Loss: 0.1423 Runtime: 6.69 s/50 iters.\n",
      "==> Epoch: 17 Step: 8850 LR: 0.000655 Total Loss: 0.0682 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 17 Step: 8900 LR: 0.000655 Total Loss: 0.4962 Runtime: 6.34 s/50 iters.\n",
      "==> Epoch: 17 Step: 8950 LR: 0.000655 Total Loss: 0.1048 Runtime: 6.14 s/50 iters.\n",
      "==> Epoch: 17 Step: 9000 LR: 0.000655 Total Loss: 0.1260 Runtime: 6.17 s/50 iters.\n",
      "==> Epoch: 17 Step: 9050 LR: 0.000655 Total Loss: 0.2552 Runtime: 6.18 s/50 iters.\n",
      "==> Epoch: 17 Step: 9100 LR: 0.000655 Total Loss: 0.1483 Runtime: 6.27 s/50 iters.\n",
      "==> Epoch: 17 Step: 9150 LR: 0.000655 Total Loss: 0.1462 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 17 Loss 0.378834 .\n",
      "==> Epoch: 18 Step: 9200 LR: 0.000794 Total Loss: 0.0434 Runtime: 2.22 s/50 iters.\n",
      "==> Epoch: 18 Step: 9250 LR: 0.000794 Total Loss: 0.0879 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 18 Step: 9300 LR: 0.000794 Total Loss: 0.1367 Runtime: 6.39 s/50 iters.\n",
      "==> Epoch: 18 Step: 9350 LR: 0.000794 Total Loss: 0.1418 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 18 Step: 9400 LR: 0.000794 Total Loss: 0.1341 Runtime: 6.11 s/50 iters.\n",
      "==> Epoch: 18 Step: 9450 LR: 0.000794 Total Loss: 0.3710 Runtime: 6.18 s/50 iters.\n",
      "==> Epoch: 18 Step: 9500 LR: 0.000794 Total Loss: 0.1446 Runtime: 6.43 s/50 iters.\n",
      "==> Epoch: 18 Step: 9550 LR: 0.000794 Total Loss: 0.1702 Runtime: 6.95 s/50 iters.\n",
      "==> Epoch: 18 Step: 9600 LR: 0.000794 Total Loss: 0.2091 Runtime: 6.83 s/50 iters.\n",
      "==> Epoch: 18 Step: 9650 LR: 0.000794 Total Loss: 0.1160 Runtime: 6.80 s/50 iters.\n",
      "==> Epoch: 18 Step: 9700 LR: 0.000794 Total Loss: 0.2644 Runtime: 6.47 s/50 iters.\n",
      "==> Epoch: 18 Loss 0.219770 .\n",
      "==> Epoch: 19 Step: 9750 LR: 0.000905 Total Loss: 0.0438 Runtime: 5.83 s/50 iters.\n",
      "==> Epoch: 19 Step: 9800 LR: 0.000905 Total Loss: 0.2329 Runtime: 6.14 s/50 iters.\n",
      "==> Epoch: 19 Step: 9850 LR: 0.000905 Total Loss: 0.3470 Runtime: 6.17 s/50 iters.\n",
      "==> Epoch: 19 Step: 9900 LR: 0.000905 Total Loss: 0.1578 Runtime: 6.15 s/50 iters.\n",
      "==> Epoch: 19 Step: 9950 LR: 0.000905 Total Loss: 0.2755 Runtime: 6.09 s/50 iters.\n",
      "==> Epoch: 19 Step: 10000 LR: 0.000905 Total Loss: 0.1061 Runtime: 6.19 s/50 iters.\n",
      "==> Epoch: 19 Step: 10050 LR: 0.000905 Total Loss: 0.1307 Runtime: 6.48 s/50 iters.\n",
      "==> Epoch: 19 Step: 10100 LR: 0.000905 Total Loss: 0.2073 Runtime: 6.66 s/50 iters.\n",
      "==> Epoch: 19 Step: 10150 LR: 0.000905 Total Loss: 0.1581 Runtime: 7.13 s/50 iters.\n",
      "==> Epoch: 19 Step: 10200 LR: 0.000905 Total Loss: 0.2263 Runtime: 6.63 s/50 iters.\n",
      "==> Epoch: 19 Loss 0.580903 .\n",
      "==> Epoch: 20 Step: 10250 LR: 0.000976 Total Loss: 0.0486 Runtime: 3.56 s/50 iters.\n",
      "==> Epoch: 20 Step: 10300 LR: 0.000976 Total Loss: 0.3526 Runtime: 5.92 s/50 iters.\n",
      "==> Epoch: 20 Step: 10350 LR: 0.000976 Total Loss: 0.0634 Runtime: 6.13 s/50 iters.\n",
      "==> Epoch: 20 Step: 10400 LR: 0.000976 Total Loss: 0.1841 Runtime: 6.07 s/50 iters.\n",
      "==> Epoch: 20 Step: 10450 LR: 0.000976 Total Loss: 0.2190 Runtime: 6.18 s/50 iters.\n",
      "==> Epoch: 20 Step: 10500 LR: 0.000976 Total Loss: 0.4777 Runtime: 6.18 s/50 iters.\n",
      "==> Epoch: 20 Step: 10550 LR: 0.000976 Total Loss: 0.1172 Runtime: 6.18 s/50 iters.\n",
      "==> Epoch: 20 Step: 10600 LR: 0.000976 Total Loss: 0.4441 Runtime: 6.15 s/50 iters.\n",
      "==> Epoch: 20 Step: 10650 LR: 0.000976 Total Loss: 0.0608 Runtime: 6.24 s/50 iters.\n",
      "==> Epoch: 20 Step: 10700 LR: 0.000976 Total Loss: 0.3348 Runtime: 6.46 s/50 iters.\n",
      "==> Epoch: 20 Loss 0.213880 .\n",
      "==> Epoch: 21 Step: 10750 LR: 0.001000 Total Loss: 0.1178 Runtime: 1.11 s/50 iters.\n",
      "==> Epoch: 21 Step: 10800 LR: 0.001000 Total Loss: 0.2404 Runtime: 5.89 s/50 iters.\n",
      "==> Epoch: 21 Step: 10850 LR: 0.001000 Total Loss: 0.1003 Runtime: 5.98 s/50 iters.\n",
      "==> Epoch: 21 Step: 10900 LR: 0.001000 Total Loss: 0.3208 Runtime: 6.09 s/50 iters.\n",
      "==> Epoch: 21 Step: 10950 LR: 0.001000 Total Loss: 0.2222 Runtime: 6.09 s/50 iters.\n",
      "==> Epoch: 21 Step: 11000 LR: 0.001000 Total Loss: 0.5065 Runtime: 6.16 s/50 iters.\n",
      "==> Epoch: 21 Step: 11050 LR: 0.001000 Total Loss: 0.1774 Runtime: 6.31 s/50 iters.\n",
      "==> Epoch: 21 Step: 11100 LR: 0.001000 Total Loss: 0.0633 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 21 Step: 11150 LR: 0.001000 Total Loss: 0.1775 Runtime: 6.35 s/50 iters.\n",
      "==> Epoch: 21 Step: 11200 LR: 0.001000 Total Loss: 0.1584 Runtime: 6.99 s/50 iters.\n",
      "==> Epoch: 21 Step: 11250 LR: 0.001000 Total Loss: 0.0504 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 21 Loss 0.303315 .\n",
      "==> Epoch: 22 Step: 11300 LR: 0.000976 Total Loss: 0.2410 Runtime: 5.45 s/50 iters.\n",
      "==> Epoch: 22 Step: 11350 LR: 0.000976 Total Loss: 0.1018 Runtime: 6.15 s/50 iters.\n",
      "==> Epoch: 22 Step: 11400 LR: 0.000976 Total Loss: 0.0532 Runtime: 6.24 s/50 iters.\n",
      "==> Epoch: 22 Step: 11450 LR: 0.000976 Total Loss: 0.0734 Runtime: 6.24 s/50 iters.\n",
      "==> Epoch: 22 Step: 11500 LR: 0.000976 Total Loss: 0.1221 Runtime: 6.33 s/50 iters.\n",
      "==> Epoch: 22 Step: 11550 LR: 0.000976 Total Loss: 0.4890 Runtime: 6.63 s/50 iters.\n",
      "==> Epoch: 22 Step: 11600 LR: 0.000976 Total Loss: 0.0450 Runtime: 6.35 s/50 iters.\n",
      "==> Epoch: 22 Step: 11650 LR: 0.000976 Total Loss: 0.1821 Runtime: 6.34 s/50 iters.\n",
      "==> Epoch: 22 Step: 11700 LR: 0.000976 Total Loss: 0.3295 Runtime: 6.13 s/50 iters.\n",
      "==> Epoch: 22 Step: 11750 LR: 0.000976 Total Loss: 0.0908 Runtime: 6.21 s/50 iters.\n",
      "==> Epoch: 22 Loss 0.252194 .\n",
      "==> Epoch: 23 Step: 11800 LR: 0.000905 Total Loss: 0.2022 Runtime: 2.54 s/50 iters.\n",
      "==> Epoch: 23 Step: 11850 LR: 0.000905 Total Loss: 0.0483 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 23 Step: 11900 LR: 0.000905 Total Loss: 0.2014 Runtime: 6.25 s/50 iters.\n",
      "==> Epoch: 23 Step: 11950 LR: 0.000905 Total Loss: 0.1247 Runtime: 6.16 s/50 iters.\n",
      "==> Epoch: 23 Step: 12000 LR: 0.000905 Total Loss: 0.0862 Runtime: 6.36 s/50 iters.\n",
      "==> Epoch: 23 Step: 12050 LR: 0.000905 Total Loss: 0.1333 Runtime: 6.11 s/50 iters.\n",
      "==> Epoch: 23 Step: 12100 LR: 0.000905 Total Loss: 0.3209 Runtime: 6.21 s/50 iters.\n",
      "==> Epoch: 23 Step: 12150 LR: 0.000905 Total Loss: 0.2047 Runtime: 6.11 s/50 iters.\n",
      "==> Epoch: 23 Step: 12200 LR: 0.000905 Total Loss: 0.1174 Runtime: 6.10 s/50 iters.\n",
      "==> Epoch: 23 Step: 12250 LR: 0.000905 Total Loss: 0.2440 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 23 Loss 0.294813 .\n",
      "==> Epoch: 24 Step: 12300 LR: 0.000794 Total Loss: 0.1042 Runtime: 0.06 s/50 iters.\n",
      "==> Epoch: 24 Step: 12350 LR: 0.000794 Total Loss: 0.3912 Runtime: 6.23 s/50 iters.\n",
      "==> Epoch: 24 Step: 12400 LR: 0.000794 Total Loss: 0.1051 Runtime: 6.33 s/50 iters.\n",
      "==> Epoch: 24 Step: 12450 LR: 0.000794 Total Loss: 0.1795 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 24 Step: 12500 LR: 0.000794 Total Loss: 0.1697 Runtime: 6.40 s/50 iters.\n",
      "==> Epoch: 24 Step: 12550 LR: 0.000794 Total Loss: 0.1976 Runtime: 6.64 s/50 iters.\n",
      "==> Epoch: 24 Step: 12600 LR: 0.000794 Total Loss: 0.0214 Runtime: 6.24 s/50 iters.\n",
      "==> Epoch: 24 Step: 12650 LR: 0.000794 Total Loss: 0.3079 Runtime: 6.05 s/50 iters.\n",
      "==> Epoch: 24 Step: 12700 LR: 0.000794 Total Loss: 0.1598 Runtime: 6.07 s/50 iters.\n",
      "==> Epoch: 24 Step: 12750 LR: 0.000794 Total Loss: 0.1469 Runtime: 6.07 s/50 iters.\n",
      "==> Epoch: 24 Step: 12800 LR: 0.000794 Total Loss: 0.0706 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 24 Loss 0.298252 .\n",
      "==> Epoch: 25 Step: 12850 LR: 0.000655 Total Loss: 0.1307 Runtime: 4.33 s/50 iters.\n",
      "==> Epoch: 25 Step: 12900 LR: 0.000655 Total Loss: 0.0865 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 25 Step: 12950 LR: 0.000655 Total Loss: 0.0813 Runtime: 6.80 s/50 iters.\n",
      "==> Epoch: 25 Step: 13000 LR: 0.000655 Total Loss: 0.1310 Runtime: 6.95 s/50 iters.\n",
      "==> Epoch: 25 Step: 13050 LR: 0.000655 Total Loss: 0.0495 Runtime: 6.95 s/50 iters.\n",
      "==> Epoch: 25 Step: 13100 LR: 0.000655 Total Loss: 0.1029 Runtime: 7.01 s/50 iters.\n",
      "==> Epoch: 25 Step: 13150 LR: 0.000655 Total Loss: 0.0685 Runtime: 6.95 s/50 iters.\n",
      "==> Epoch: 25 Step: 13200 LR: 0.000655 Total Loss: 0.1046 Runtime: 6.95 s/50 iters.\n",
      "==> Epoch: 25 Step: 13250 LR: 0.000655 Total Loss: 0.0603 Runtime: 6.93 s/50 iters.\n",
      "==> Epoch: 25 Step: 13300 LR: 0.000655 Total Loss: 0.0768 Runtime: 6.94 s/50 iters.\n",
      "==> Epoch: 25 Loss 0.213443 .\n",
      "==> Epoch: 26 Step: 13350 LR: 0.000500 Total Loss: 0.1073 Runtime: 1.98 s/50 iters.\n",
      "==> Epoch: 26 Step: 13400 LR: 0.000500 Total Loss: 0.0576 Runtime: 5.92 s/50 iters.\n",
      "==> Epoch: 26 Step: 13450 LR: 0.000500 Total Loss: 0.0319 Runtime: 5.98 s/50 iters.\n",
      "==> Epoch: 26 Step: 13500 LR: 0.000500 Total Loss: 0.0229 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 26 Step: 13550 LR: 0.000500 Total Loss: 0.0142 Runtime: 6.06 s/50 iters.\n",
      "==> Epoch: 26 Step: 13600 LR: 0.000500 Total Loss: 0.2203 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 26 Step: 13650 LR: 0.000500 Total Loss: 0.0151 Runtime: 6.09 s/50 iters.\n",
      "==> Epoch: 26 Step: 13700 LR: 0.000500 Total Loss: 0.0119 Runtime: 6.12 s/50 iters.\n",
      "==> Epoch: 26 Step: 13750 LR: 0.000500 Total Loss: 0.0690 Runtime: 6.10 s/50 iters.\n",
      "==> Epoch: 26 Step: 13800 LR: 0.000500 Total Loss: 0.0208 Runtime: 6.11 s/50 iters.\n",
      "==> Epoch: 26 Step: 13850 LR: 0.000500 Total Loss: 0.0411 Runtime: 6.06 s/50 iters.\n",
      "==> Epoch: 26 Loss 0.223801 .\n",
      "==> Epoch: 27 Step: 13900 LR: 0.000345 Total Loss: 0.0502 Runtime: 5.43 s/50 iters.\n",
      "==> Epoch: 27 Step: 13950 LR: 0.000345 Total Loss: 0.0580 Runtime: 5.92 s/50 iters.\n",
      "==> Epoch: 27 Step: 14000 LR: 0.000345 Total Loss: 0.0442 Runtime: 6.02 s/50 iters.\n",
      "==> Epoch: 27 Step: 14050 LR: 0.000345 Total Loss: 0.0493 Runtime: 6.04 s/50 iters.\n",
      "==> Epoch: 27 Step: 14100 LR: 0.000345 Total Loss: 0.0779 Runtime: 6.05 s/50 iters.\n",
      "==> Epoch: 27 Step: 14150 LR: 0.000345 Total Loss: 0.0317 Runtime: 6.09 s/50 iters.\n",
      "==> Epoch: 27 Step: 14200 LR: 0.000345 Total Loss: 0.0790 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 27 Step: 14250 LR: 0.000345 Total Loss: 0.3510 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 27 Step: 14300 LR: 0.000345 Total Loss: 0.0552 Runtime: 6.06 s/50 iters.\n",
      "==> Epoch: 27 Step: 14350 LR: 0.000345 Total Loss: 0.0785 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 27 Loss 0.248905 .\n",
      "==> Epoch: 28 Step: 14400 LR: 0.000206 Total Loss: 0.0231 Runtime: 3.23 s/50 iters.\n",
      "==> Epoch: 28 Step: 14450 LR: 0.000206 Total Loss: 0.0041 Runtime: 5.90 s/50 iters.\n",
      "==> Epoch: 28 Step: 14500 LR: 0.000206 Total Loss: 0.0731 Runtime: 6.02 s/50 iters.\n",
      "==> Epoch: 28 Step: 14550 LR: 0.000206 Total Loss: 0.0304 Runtime: 6.07 s/50 iters.\n",
      "==> Epoch: 28 Step: 14600 LR: 0.000206 Total Loss: 0.0233 Runtime: 6.09 s/50 iters.\n",
      "==> Epoch: 28 Step: 14650 LR: 0.000206 Total Loss: 0.0608 Runtime: 6.12 s/50 iters.\n",
      "==> Epoch: 28 Step: 14700 LR: 0.000206 Total Loss: 0.0033 Runtime: 6.04 s/50 iters.\n",
      "==> Epoch: 28 Step: 14750 LR: 0.000206 Total Loss: 0.0870 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 28 Step: 14800 LR: 0.000206 Total Loss: 0.0346 Runtime: 6.06 s/50 iters.\n",
      "==> Epoch: 28 Step: 14850 LR: 0.000206 Total Loss: 0.0036 Runtime: 6.07 s/50 iters.\n",
      "==> Epoch: 28 Loss 0.282754 .\n",
      "==> Epoch: 29 Step: 14900 LR: 0.000095 Total Loss: 0.0018 Runtime: 0.98 s/50 iters.\n",
      "==> Epoch: 29 Step: 14950 LR: 0.000095 Total Loss: 0.0219 Runtime: 5.89 s/50 iters.\n",
      "==> Epoch: 29 Step: 15000 LR: 0.000095 Total Loss: 0.0706 Runtime: 6.01 s/50 iters.\n",
      "==> Epoch: 29 Step: 15050 LR: 0.000095 Total Loss: 0.0111 Runtime: 6.09 s/50 iters.\n",
      "==> Epoch: 29 Step: 15100 LR: 0.000095 Total Loss: 0.0078 Runtime: 6.04 s/50 iters.\n",
      "==> Epoch: 29 Step: 15150 LR: 0.000095 Total Loss: 0.0081 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 29 Step: 15200 LR: 0.000095 Total Loss: 0.0976 Runtime: 6.07 s/50 iters.\n",
      "==> Epoch: 29 Step: 15250 LR: 0.000095 Total Loss: 0.0289 Runtime: 6.15 s/50 iters.\n",
      "==> Epoch: 29 Step: 15300 LR: 0.000095 Total Loss: 0.0022 Runtime: 6.12 s/50 iters.\n",
      "==> Epoch: 29 Step: 15350 LR: 0.000095 Total Loss: 0.0335 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 29 Step: 15400 LR: 0.000095 Total Loss: 0.0050 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 29 Loss 0.265176 .\n",
      "==> Epoch: 30 Step: 15450 LR: 0.000024 Total Loss: 0.0052 Runtime: 4.68 s/50 iters.\n",
      "==> Epoch: 30 Step: 15500 LR: 0.000024 Total Loss: 0.0054 Runtime: 5.94 s/50 iters.\n",
      "==> Epoch: 30 Step: 15550 LR: 0.000024 Total Loss: 0.0195 Runtime: 6.01 s/50 iters.\n",
      "==> Epoch: 30 Step: 15600 LR: 0.000024 Total Loss: 0.0069 Runtime: 6.05 s/50 iters.\n",
      "==> Epoch: 30 Step: 15650 LR: 0.000024 Total Loss: 0.0035 Runtime: 6.06 s/50 iters.\n",
      "==> Epoch: 30 Step: 15700 LR: 0.000024 Total Loss: 0.0008 Runtime: 6.08 s/50 iters.\n",
      "==> Epoch: 30 Step: 15750 LR: 0.000024 Total Loss: 0.1782 Runtime: 6.07 s/50 iters.\n",
      "==> Epoch: 30 Step: 15800 LR: 0.000024 Total Loss: 0.0237 Runtime: 6.16 s/50 iters.\n",
      "==> Epoch: 30 Step: 15850 LR: 0.000024 Total Loss: 0.0086 Runtime: 6.05 s/50 iters.\n",
      "==> Epoch: 30 Step: 15900 LR: 0.000024 Total Loss: 0.0025 Runtime: 6.04 s/50 iters.\n",
      "==> Epoch: 30 Loss 0.283443 .\n",
      "==> Runtime: 46.78 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Train the model, \n",
    "#DONT FORGET TO DELETE CHECKPOINTS\n",
    "My_model = trainer.train(my_extended_model).cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
