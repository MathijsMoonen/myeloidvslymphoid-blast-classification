{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e66518e-71cb-4c3d-bccf-f85f17d8b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import  glob\n",
    "import time\n",
    "import albumentations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from utils.utils import segment_cell\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder# creating instance of one-hot-encoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "### Internal Imports\n",
    "from models.ResNext50 import Myresnext50\n",
    "from train.train_classification import trainer_classification\n",
    "from utils.utils import configure_optimizers\n",
    "from Datasets.DataLoader import Img_DataLoader\n",
    "\n",
    "### PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe32bca7-aab5-41df-afd9-98727f30a1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original set shape: (20594, 4)          Training set label count: {'Other': 11821, 'Myeloid': 7576, 'Lymphoid': 1197} \n",
      "\n",
      "Training set shape: (16475, 4)          Training set label count: {'Other': 9457, 'Myeloid': 6061, 'Lymphoid': 957} \n",
      "\n",
      "Validation set shape: (2059, 4)         Validation set label count: {'Other': 1182, 'Myeloid': 757, 'Lymphoid': 120} \n",
      "\n",
      "Test set shape: (2060, 4)         Validation set label count: {'Other': 1182, 'Myeloid': 758, 'Lymphoid': 120} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data, split it into training and validation dataframes\n",
    "df = pd.read_pickle('notextimagepaths.pkl')\n",
    "\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.20, random_state=42, stratify=df['Label'])\n",
    "val_df, test_df = train_test_split(val_df, test_size=0.5, random_state=42, stratify=val_df['Label'])\n",
    "\n",
    "print(f\"Original set shape: {df.shape}          Training set label count: {str(Counter(df['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "print(f\"Training set shape: {train_df.shape}          Training set label count: {str(Counter(train_df['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "print(f\"Validation set shape: {val_df.shape}         Validation set label count: {str(Counter(val_df['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "print(f\"Test set shape: {test_df.shape}         Validation set label count: {str(Counter(test_df['Label'].to_list()))[7:][1:][:-1]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037f2d57-2fd0-4995-8f5f-72f4e3d87295",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Code used to store each image with removed text in a separate folder, such that it doesnt have to be done during training thus saving much time\n",
    "# df = pd.read_pickle('imagepaths.pkl')\n",
    "\n",
    "# def remove_text(filepath):\n",
    "\n",
    "#     # Load image\n",
    "#     img = cv2.imread(filepath)\n",
    "#     img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     # Step 1: Copy the image\n",
    "#     img_segmented = img_rgb.copy()\n",
    "    \n",
    "#     # Step 2: Define region to black out (bottom-right corner)\n",
    "#     height, width, _ = img_segmented.shape\n",
    "#     corner_hmin = int(height * 0.15)  # bottom 10%\n",
    "#     corner_hmax = int(height * 0.05)  # bottom 5%\n",
    "#     corner_w = int(width * 0.42)   # rightmost 25%\n",
    "    \n",
    "#     # Step 3: Black out that region\n",
    "#     img_segmented[height - corner_hmin : height - corner_hmax, 0 : corner_w] = 0  # set to black\n",
    "        \n",
    "#     return img_rgb, img_segmented\n",
    "\n",
    "# filepaths = df['Filepath'].tolist()\n",
    "\n",
    "# for filepath in filepaths:\n",
    "#     filename =  filepath.split('\\\\')[-1]\n",
    "#     orig_img, seg_img = remove_text(filepath)\n",
    "#     img_bgr = cv2.cvtColor(seg_img, cv2.COLOR_RGB2BGR)\n",
    "#     cv2.imwrite(os.path.join('Datasets/notextimages', filename), img_bgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49be3e84-3648-41d0-bd09-3ec7f9e0f754",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# For testing purposes to check whether a model trained on no data indeed performs poorly, thus ensuring that there is no label leakage during evaluation\n",
    "\n",
    "# train_df_w, train_df_small = train_test_split(train_df, test_size=0.003, random_state=42, stratify=train_df['Label'])\n",
    "# val_df_w, val_df_small = train_test_split(val_df, test_size=0.05, random_state=42, stratify=val_df['Label'])\n",
    "# test_df_w, test_df_small = train_test_split(test_df, test_size=0.05, random_state=42, stratify=test_df['Label'])\n",
    "\n",
    "# print(f\"Training set shape: {train_df_small.shape}          Training set label count: {str(Counter(train_df_small['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "# print(f\"Validation set shape: {val_df_small.shape}         Validation set label count: {str(Counter(val_df_small['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "# print(f\"Test set shape: {test_df_small.shape}         Validation set label count: {str(Counter(test_df_small['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "\n",
    "# # Load df that represents the one hot encoding of each cell type (Myeloid, Lymphoid, other)\n",
    "# cell_types_df = pd.read_pickle(\"cell_types_df.pkl\")\n",
    "\n",
    "# # Load model\n",
    "# resnext50_pretrained = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\n",
    "# my_extended_model = Myresnext50(my_pretrained_model= resnext50_pretrained, num_classes = 3)\n",
    "\n",
    "# X_train_small = train_df_small['Filepath'].to_list()\n",
    "# X_val_small = val_df_small['Filepath'].to_list()\n",
    "\n",
    "# # Load labels\n",
    "# train_labels_small = train_df_small['Label'].to_list()\n",
    "# validation_labels_small = val_df_small['Label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba1fe00a-3ec1-4575-b1d1-6e81abc5f2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\moone/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
      "C:\\Users\\moone\\miniconda3\\envs\\thesis\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\moone\\miniconda3\\envs\\thesis\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load filepaths\n",
    "X_train = train_df['Filepath'].to_list()\n",
    "X_val = val_df['Filepath'].to_list()\n",
    "\n",
    "# Load labels\n",
    "train_labels = train_df['Label'].to_list()\n",
    "validation_labels = val_df['Label'].to_list()\n",
    "\n",
    "# Load df that represents the one hot encoding of each cell type (Myeloid, Lymphoid, other)\n",
    "cell_types_df = pd.read_pickle(\"cell_types_df.pkl\")\n",
    "\n",
    "# Load model\n",
    "resnext50_pretrained = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\n",
    "my_extended_model = Myresnext50(my_pretrained_model= resnext50_pretrained, num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67a3ea6b-a52c-4ac3-bd4d-de5aeab45789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple augumentation to improve the data generalibility\n",
    "\n",
    "transform_pipeline = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e317cbab-fa58-4e9e-ab1b-4d9ce018e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training setup\n",
    "trainer = trainer_classification(train_image_files=X_train, validation_image_files=X_val, train_labels=train_labels, validation_labels=validation_labels, model=my_extended_model,\n",
    "                                     img_transform=transform_pipeline, init_lr=0.001,\n",
    "                                     Tmax=30,\n",
    "\n",
    "                                     weight_decay=0.0005, batch_size=32, epochs=30, df=cell_types_df,\n",
    "                                     save_checkpoints_dir='checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e3c9e8-3c3a-41f4-bcf1-ee89be97997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes\n",
    "\n",
    "# dataset = Img_DataLoader(img_list=X_train, labels=train_labels, split='train', transform = transform_pipeline, df = cell_types_df)\n",
    "# shuffle = True\n",
    "# dataloader = DataLoader(dataset, batch_size=32, num_workers=2, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1af3c-b8a7-4109-8ac0-2aca530a0d37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Delete checkpoints of previous models\n",
    "directory = \"checkpoints/\"\n",
    "\n",
    "for i in range(30):\n",
    "    filename = f\"checkpoint_{i}_iteration.ckpt\"\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    \n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "        print(f\"Deleted: {file_path}\")\n",
    "\n",
    "# Train the model\n",
    "My_model = trainer.train(my_extended_model).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
