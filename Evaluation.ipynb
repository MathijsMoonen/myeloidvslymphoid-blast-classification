{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a01dd4",
   "metadata": {},
   "source": [
    "##### Iain's comments\n",
    "In some of the cases it would be good to use more informative variable names e.g. _res, _class, etc. I would change res to pred_score, pred_prob, or pred_logists or something like that.\n",
    "The function roc_auc_score_multiclass() is missing index in the argument.\n",
    "I’m pretty sure pred_class should be named pred_proba/pred_score etc, not pred_class (pred_class sounds like it is the predicted class, but this is actually a continuous prediction).\n",
    "Double check if there is a problem with precision_score.recall_score/f1_score and the pos_label argument e.g. the positive label should be 1.\n",
    "In roc_auc_score_multiclass(), I would make the elements of eval_dict a dict, not a list where you have to remember the order of the input (see attached script)\n",
    "I’ve attached a script for  computing various multiclass classification metrics. It’s not finished, but it’s a bit more streamlined and will give us more information. For classification – especially mutlitclass problems – we want to compute a ton of metrics to help understand what’s going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce70eebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import  glob\n",
    "import time\n",
    "import albumentations\n",
    "import math\n",
    "import shutil\n",
    "from collections import Counter\n",
    "from scipy.special import softmax\n",
    "from sklearn.preprocessing import OneHotEncoder# creating instance of one-hot-encoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from models.ResNext50 import Myresnext50\n",
    "from train.train_classification import trainer_classification\n",
    "from utils.utils import configure_optimizers\n",
    "from Datasets.DataLoader import Img_DataLoader\n",
    "\n",
    "### PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ce15a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ORIGINAL CODE BY DEEPHEME, REPLACED BY CELL BELOW BUT KEPT FOR REFERENCE\n",
    "# X_train = glob.glob('../../2022_05_18_cells_50_NORMAL/Cross_Validation/iteration_3/train/*/*')\n",
    "# X_val = glob.glob('../../2022_05_18_cells_50_NORMAL/Cross_Validation/iteration_3/val/*/*')\n",
    "\n",
    "# labels = [x.split('/')[-2] for x in X_train]\n",
    "# cell_types = set(labels)\n",
    "\n",
    "# cell_types = list(cell_types)\n",
    "# cell_types.sort()\n",
    "\n",
    "# cell_types_df = pd.DataFrame(cell_types, columns=['Cell_Types'])# converting type of columns to 'category'\n",
    "# cell_types_df['Cell_Types'] = cell_types_df['Cell_Types'].astype('category')# Assigning numerical values and storing in another column\n",
    "# cell_types_df['Cell_Types_Cat'] = cell_types_df['Cell_Types'].cat.codes\n",
    "\n",
    "# enc = OneHotEncoder(handle_unknown='ignore')# passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "# enc_df = pd.DataFrame(enc.fit_transform(cell_types_df[['Cell_Types_Cat']]).toarray())# merge with main df bridge_df on key values\n",
    "# cell_types_df = cell_types_df.join(enc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d9cad5f-d8a2-431a-9962-d683b361e324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (17669, 4)\n",
      "Validation set shape: (3119, 4)\n"
     ]
    }
   ],
   "source": [
    "# Augmented code to store the data in two folders, uncomment if you want to store the files in a directory\n",
    "\n",
    "# # Read data\n",
    "# cell_types_df = pd.read_pickle(\"imagepaths.pkl\")\n",
    "\n",
    "# # First split into training and validation sets\n",
    "# train_df, val_df = train_test_split(cell_types_df, test_size=0.15, random_state=42, stratify=cell_types_df['Label'])\n",
    "# print(f\"Training set shape: {train_df.shape}\\nValidation set shape: {val_df.shape}\")\n",
    "\n",
    "# # Copy the images of the training and validation sets into a directory to use the same approach as Deepheme\n",
    "# def copy_images(df_subset, target_dir):\n",
    "#     for file_path in df_subset['Filepath']:\n",
    "#         # Get just the filename (without directories)\n",
    "#         file_name = os.path.basename(file_path)\n",
    "#         # Define the destination path\n",
    "#         dest_path = os.path.join(target_dir, file_name)\n",
    "#         # Copy the file\n",
    "#         shutil.copy(file_path, dest_path)\n",
    "\n",
    "# # Copy images, uncomment below if you haven't copied them yet\n",
    "# copy_images(train_df, 'Datasets/trainingset')\n",
    "# copy_images(val_df, 'Datasets/validationset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6f5941a-2914-4e61-aa2e-09f5e1fc6508",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Augmented code to read the data, only uncomment if you dont have cell_types_df.pkl\n",
    "\n",
    "# cell_types_df = pd.read_pickle(\"imagepaths.pkl\")\n",
    "\n",
    "# cell_types_df = cell_types_df.rename(columns={\"Filepath\":\"Filepath\", \"Label\":\"Cell_Types\"}) # To align with the names used for Deepheme\n",
    "# cell_types_df['Cell_Types'] = cell_types_df['Cell_Types'].astype('category') # Converting type of columns to 'category'\n",
    "# cell_types_df['Cell_Types_Cat'] = cell_types_df['Cell_Types'].cat.codes # Assigning a numerical value to each category and storing in another column\n",
    "\n",
    "# # Create one hot encoding for each category\n",
    "# enc = OneHotEncoder(handle_unknown='ignore') # passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "# enc_df = pd.DataFrame(enc.fit_transform(cell_types_df[['Cell_Types_Cat']]).toarray()) # merge with main df bridge_df on key values\n",
    "# cell_types_df = cell_types_df.join(enc_df)\n",
    "\n",
    "# #drop duplicates to create a reference list of the encoding for later use\n",
    "# cell_types_df = cell_types_df.drop_duplicates(subset = 'Cell_Types', keep='first')\n",
    "\n",
    "# # Store in pickle file for reuse\n",
    "# cell_types_df.to_pickle(\"cell_types_df.pkl\")\n",
    "# cell_types_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8680e8a6-a0e1-425c-a729-95d51ab73c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filepath</th>\n",
       "      <th>Cell_Types</th>\n",
       "      <th>Final diagnosis</th>\n",
       "      <th>Classnames</th>\n",
       "      <th>Cell_Types_Cat</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>D:\\Mathijs\\Open Universiteit\\Thesis\\Implementa...</td>\n",
       "      <td>Other</td>\n",
       "      <td>AML</td>\n",
       "      <td>LY</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D:\\Mathijs\\Open Universiteit\\Thesis\\Implementa...</td>\n",
       "      <td>Myeloid</td>\n",
       "      <td>AML</td>\n",
       "      <td>BL</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>D:\\Mathijs\\Open Universiteit\\Thesis\\Implementa...</td>\n",
       "      <td>Lymphoid</td>\n",
       "      <td>B-ALL</td>\n",
       "      <td>BL</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Filepath Cell_Types  \\\n",
       "0   D:\\Mathijs\\Open Universiteit\\Thesis\\Implementa...      Other   \n",
       "1   D:\\Mathijs\\Open Universiteit\\Thesis\\Implementa...    Myeloid   \n",
       "35  D:\\Mathijs\\Open Universiteit\\Thesis\\Implementa...   Lymphoid   \n",
       "\n",
       "   Final diagnosis Classnames  Cell_Types_Cat    0    1    2  \n",
       "0              AML         LY               2  0.0  0.0  1.0  \n",
       "1              AML         BL               1  0.0  1.0  0.0  \n",
       "35           B-ALL         BL               0  1.0  0.0  0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_types_df = pd.read_pickle(\"cell_types_df.pkl\")\n",
    "cell_types_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b0fb0e3-66f9-46dd-892c-772d6e813388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (17669, 4)          Training set label count: {'Other': 10069, 'Myeloid': 6582, 'Lymphoid': 1018} \n",
      "\n",
      "Validation set shape: (3119, 4)         Validation set label count: {'Other': 1777, 'Myeloid': 1162, 'Lymphoid': 180} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data, split it into training and validation dataframes\n",
    "df = pd.read_pickle('imagepaths.pkl')\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.15, random_state=42, stratify=df['Label'])\n",
    "print(f\"Training set shape: {train_df.shape}          Training set label count: {str(Counter(train_df['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "print(f\"Validation set shape: {val_df.shape}         Validation set label count: {str(Counter(val_df['Label'].to_list()))[7:][1:][:-1]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0af4184",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple normalization to improve the data generalibility\n",
    "\n",
    "transform_pipeline = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ab30a1f-0b78-468d-abf8-a21bfb40e666",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\moone/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    }
   ],
   "source": [
    "resnext50_pretrained = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d')\n",
    "My_model = Myresnext50(my_pretrained_model= resnext50_pretrained, num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7e46fed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to C:\\Users\\moone/.cache\\torch\\hub\\v0.10.0.zip\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Result/ResNeXt50_pretrained/C_V/control/checkpoint_best_iteration3.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m My_model \u001b[38;5;241m=\u001b[39m Myresnext50(my_pretrained_model\u001b[38;5;241m=\u001b[39m resnext50_pretrained, num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m23\u001b[39m)\n\u001b[0;32m      4\u001b[0m checkpoint_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../Result/ResNeXt50_pretrained/C_V/control/checkpoint_best_iteration3.ckpt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 5\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Function to remove 'module.' from the checkpoints, which must be removed because we do not use torch.nn.DataParallel\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OrderedDict\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\thesis\\lib\\site-packages\\torch\\serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Result/ResNeXt50_pretrained/C_V/control/checkpoint_best_iteration3.ckpt'"
     ]
    }
   ],
   "source": [
    "# Run this cell if you want to utilize checkpoints, otherwise run cell above\n",
    "resnext50_pretrained = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d')\n",
    "My_model = Myresnext50(my_pretrained_model= resnext50_pretrained, num_classes = 3)\n",
    "\n",
    "checkpoint_PATH = '../Result/ResNeXt50_pretrained/C_V/control/checkpoint_best_iteration3.ckpt'\n",
    "checkpoint = torch.load(checkpoint_PATH)\n",
    "\n",
    "# Function to remove 'module.' from the checkpoints, which must be removed because we do not use torch.nn.DataParallel\n",
    "from collections import OrderedDict\n",
    "def remove_data_parallel(old_state_dict):\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in old_state_dict.items():\n",
    "        \n",
    "        name = k[7:] # remove `module.`\n",
    "        \n",
    "        new_state_dict[name] = v\n",
    "    \n",
    "    return new_state_dict\n",
    "\n",
    "checkpoint  = remove_data_parallel(checkpoint['model_state_dict'])\n",
    "\n",
    "My_model.load_state_dict(checkpoint, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7219444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aa-ssun2-cmp/anaconda3/envs/Harry_Img/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5959, 23)\n",
      "(5959, 23)\n",
      "(5959, 1000)\n",
      "5959\n",
      "(5959, 23)\n"
     ]
    }
   ],
   "source": [
    "#X_test_orig = cellnames[cellnames['dir'].isin(X_test)]\n",
    "My_model = My_model.cuda().eval()\n",
    "Orig_img = Img_DataLoader(img_list= X_val, split='viz',df= cell_types_df,transform = transform_pipeline)\n",
    "shuffle = False\n",
    "dataloader = DataLoader(Orig_img, batch_size=32, num_workers=2, shuffle=shuffle)\n",
    "\n",
    "\n",
    "for i, _batch in enumerate(dataloader):\n",
    "    \n",
    "    if i == 0:\n",
    "\n",
    "        images = _batch[\"image\"].cuda()\n",
    "        label = _batch[\"label\"]\n",
    "        ID    = [x.split('/')[-2]+\"_\"+x.split('/')[-1] for x in _batch['ID']]\n",
    "        pred_prob = My_model(images)\n",
    "        pred_hidden_layer = My_model.pretrained(images)\n",
    "\n",
    "        pred_prob = torch.flatten(pred_prob, start_dim=1).detach().cpu().numpy()\n",
    "        label = torch.flatten(label, start_dim=1).cpu().numpy()\n",
    "        pred_hidden_layer = torch.flatten(pred_hidden_layer, start_dim=1).detach().cpu().numpy()\n",
    "    else:\n",
    "        images = _batch[\"image\"].cuda()\n",
    "        _label = _batch[\"label\"]\n",
    "        _ID    = [x.split('/')[-2]+\"_\"+x.split('/')[-1] for x in _batch['ID']]\n",
    "        _pred_prob = My_model(images)\n",
    "        _pred_hidden_layer = My_model.pretrained(images)\n",
    "        \n",
    "        _pred_prob = torch.flatten(_pred_prob, start_dim=1).detach().cpu().numpy()\n",
    "        _label = torch.flatten(_label, start_dim=1).cpu().numpy()  \n",
    "        _pred_hidden_layer = torch.flatten(_pred_hidden_layer, start_dim=1).detach().cpu().numpy()\n",
    "        \n",
    "        ID = ID + _ID\n",
    "        pred_prob = np.concatenate((pred_prob, _pred_prob))\n",
    "        label = np.concatenate((label, _label))\n",
    "        pred_hidden_layer = np.concatenate((pred_hidden_layer, _pred_hidden_layer))\n",
    "pred_prob = softmax(pred_prob, axis=1)\n",
    "print(pred_prob.shape)\n",
    "print(label.shape)\n",
    "print(pred_hidden_layer.shape)\n",
    "print(len(ID))\n",
    "#pred_class_binary = np.where(res,np.max(res, axis =1))\n",
    "\n",
    "for i in range(pred_prob.shape[0]):\n",
    "    if i == 0:\n",
    "        predict_class = np.where(pred_prob[i] == np.max(pred_prob[i]),1,0).reshape(1,23)\n",
    "    else:\n",
    "        _predict_class = np.where(pred_prob[i] == np.max(pred_prob[i]),1,0).reshape(1,23)\n",
    "        predict_class = np.concatenate((predict_class, _predict_class), axis =0)\n",
    "print(predict_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b982858",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.DataFrame(data=label, index=ID, columns=cell_types_df['Cell_Types'].tolist())\n",
    "pred_prob = pd.DataFrame(data=pred_prob, index=ID, columns=cell_types_df['Cell_Types'].tolist())\n",
    "pred_class = pd.DataFrame(data=predict_class, index=ID, columns=cell_types_df['Cell_Types'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b2d8d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B1': [0.9904544453123436, 0.87292817679558, 0.9961402919953012, 0.8229166666666666, 0.9294117647058824], 'B2': [0.9183891784561926, 0.7931034482758621, 0.9979862393018963, 0.9583333333333334, 0.6764705882352942], 'E0': [0.9910738900375731, 0.9379968203497616, 0.9934552777311629, 0.9516129032258065, 0.9247648902821317], 'E4': [0.9768431265262283, 0.75, 0.9939587179056889, 0.7012987012987013, 0.8059701492537313], 'ER1': [0.988114981684708, 0.7397260273972603, 0.9744923644906863, 0.717607973421927, 0.7632508833922261], 'ER2': [0.9810824798117065, 0.7717041800643087, 0.9761704984057727, 0.7619047619047619, 0.7817589576547231], 'ER3': [0.9866138823229731, 0.8422496570644717, 0.9807014599765062, 0.8872832369942196, 0.8015665796344648], 'ER4': [0.9979856184165578, 0.9234629861982434, 0.9897633831179729, 0.8846153846153846, 0.9658792650918635], 'ER5': [0.9982017912423314, 0.9520000000000001, 0.9959724786037926, 0.918918918918919, 0.9875518672199171], 'ER6': [0.9842606862966932, 0.9491525423728814, 0.9959724786037926, 0.9911504424778761, 0.9105691056910569], 'L2': [0.9922320756819559, 0.9444444444444444, 0.9895955697264641, 0.9512635379061372, 0.9377224199288257], 'L4': [0.9962497530132385, 0.9214092140921408, 0.9951334116462494, 0.8762886597938144, 0.9714285714285714], 'M1': [0.9726985730570863, 0.7198228128460686, 0.9575432119483135, 0.7437070938215103, 0.6974248927038627], 'M2': [0.986949917142331, 0.8302238805970149, 0.9694579627454271, 0.8180147058823529, 0.8428030303030303], 'M3': [0.9886314334717607, 0.8236559139784946, 0.9724786037925827, 0.8626126126126126, 0.7880658436213992], 'M4': [0.988121792290137, 0.8200000000000001, 0.9758348716227555, 0.784688995215311, 0.8586387434554974], 'M5': [0.992024308673413, 0.8323529411764706, 0.9808692733680148, 0.827485380116959, 0.8372781065088757], 'M6': [0.9931758197772232, 0.863961813842482, 0.9904346366840073, 0.923469387755102, 0.8116591928251121], 'MO2': [0.9809609744435958, 0.7830985915492957, 0.9870783688538345, 0.7853107344632768, 0.7808988764044944], 'PL2': [0.998771058727604, 0.9727891156462585, 0.9986574928679308, 0.9662162162162162, 0.9794520547945206], 'PL3': [1.0, 0.9090909090909091, 0.9998321866084914, 0.8333333333333334, 1.0], 'PL4': [0.9982650548466533, 0.28571428571428575, 0.9983218660849136, 0.18181818181818182, 0.6666666666666666], 'U1': [0.9889311691142953, 0.9121338912133891, 0.9964759187783185, 0.923728813559322, 0.9008264462809917]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (roc_auc_score, accuracy_score, recall_score, precision_score, f1_score)\n",
    "from scipy.special import softmax\n",
    "def evaluation_metrics_multiclass(label, pred_prob, pred_class):\n",
    "    #creating a set of all the unique classes using the actual class list\n",
    "    classes = label.columns\n",
    "    eval_dict = {}\n",
    "    \n",
    "    for per_class in classes:\n",
    "        #creating a list of all the classes except the current class \n",
    "        groundtruth_per_class  = label[per_class].tolist()\n",
    "        pred_prob_per_class    = pred_prob[per_class].tolist()\n",
    "        pred_class_per_class = pred_class[per_class].tolist()\n",
    "        #marking the current class as 1 and all other classes as 0\n",
    "\n",
    "        roc_auc = roc_auc_score(groundtruth_per_class, pred_prob_per_class)\n",
    "        f1 = f1_score(groundtruth_per_class, pred_class_per_class)\n",
    "        acc = accuracy_score(groundtruth_per_class, pred_class_per_class)\n",
    "        precision = precision_score(groundtruth_per_class, pred_class_per_class)\n",
    "        recall = recall_score(groundtruth_per_class, pred_class_per_class)\n",
    "        used_metrics = ['AUC','F1','Acc','Precision','Recall']\n",
    "        eval_dict[per_class] = [roc_auc, f1, acc, precision, recall]\n",
    "\n",
    "    return eval_dict\n",
    "\n",
    "\n",
    "# assuming your already have a list of actual_class and predicted_class from the logistic regression classifier\n",
    "multiclass = evaluation_metrics_multiclass(label, pred_prob, pred_class)\n",
    "print(multiclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12f41ed0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>0.990454</td>\n",
       "      <td>0.872928</td>\n",
       "      <td>0.996140</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.929412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>0.918389</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.997986</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.676471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E0</th>\n",
       "      <td>0.991074</td>\n",
       "      <td>0.937997</td>\n",
       "      <td>0.993455</td>\n",
       "      <td>0.951613</td>\n",
       "      <td>0.924765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E4</th>\n",
       "      <td>0.976843</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.993959</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER1</th>\n",
       "      <td>0.988115</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.974492</td>\n",
       "      <td>0.717608</td>\n",
       "      <td>0.763251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER2</th>\n",
       "      <td>0.981082</td>\n",
       "      <td>0.771704</td>\n",
       "      <td>0.976170</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.781759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER3</th>\n",
       "      <td>0.986614</td>\n",
       "      <td>0.842250</td>\n",
       "      <td>0.980701</td>\n",
       "      <td>0.887283</td>\n",
       "      <td>0.801567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER4</th>\n",
       "      <td>0.997986</td>\n",
       "      <td>0.923463</td>\n",
       "      <td>0.989763</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.965879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER5</th>\n",
       "      <td>0.998202</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>0.995972</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>0.987552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER6</th>\n",
       "      <td>0.984261</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.995972</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>0.910569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>0.992232</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.989596</td>\n",
       "      <td>0.951264</td>\n",
       "      <td>0.937722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L4</th>\n",
       "      <td>0.996250</td>\n",
       "      <td>0.921409</td>\n",
       "      <td>0.995133</td>\n",
       "      <td>0.876289</td>\n",
       "      <td>0.971429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M1</th>\n",
       "      <td>0.972699</td>\n",
       "      <td>0.719823</td>\n",
       "      <td>0.957543</td>\n",
       "      <td>0.743707</td>\n",
       "      <td>0.697425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M2</th>\n",
       "      <td>0.986950</td>\n",
       "      <td>0.830224</td>\n",
       "      <td>0.969458</td>\n",
       "      <td>0.818015</td>\n",
       "      <td>0.842803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M3</th>\n",
       "      <td>0.988631</td>\n",
       "      <td>0.823656</td>\n",
       "      <td>0.972479</td>\n",
       "      <td>0.862613</td>\n",
       "      <td>0.788066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M4</th>\n",
       "      <td>0.988122</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.975835</td>\n",
       "      <td>0.784689</td>\n",
       "      <td>0.858639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M5</th>\n",
       "      <td>0.992024</td>\n",
       "      <td>0.832353</td>\n",
       "      <td>0.980869</td>\n",
       "      <td>0.827485</td>\n",
       "      <td>0.837278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M6</th>\n",
       "      <td>0.993176</td>\n",
       "      <td>0.863962</td>\n",
       "      <td>0.990435</td>\n",
       "      <td>0.923469</td>\n",
       "      <td>0.811659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MO2</th>\n",
       "      <td>0.980961</td>\n",
       "      <td>0.783099</td>\n",
       "      <td>0.987078</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.780899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL2</th>\n",
       "      <td>0.998771</td>\n",
       "      <td>0.972789</td>\n",
       "      <td>0.998657</td>\n",
       "      <td>0.966216</td>\n",
       "      <td>0.979452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.999832</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL4</th>\n",
       "      <td>0.998265</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.998322</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U1</th>\n",
       "      <td>0.988931</td>\n",
       "      <td>0.912134</td>\n",
       "      <td>0.996476</td>\n",
       "      <td>0.923729</td>\n",
       "      <td>0.900826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AUC        F1       Acc  Precision    Recall\n",
       "B1   0.990454  0.872928  0.996140   0.822917  0.929412\n",
       "B2   0.918389  0.793103  0.997986   0.958333  0.676471\n",
       "E0   0.991074  0.937997  0.993455   0.951613  0.924765\n",
       "E4   0.976843  0.750000  0.993959   0.701299  0.805970\n",
       "ER1  0.988115  0.739726  0.974492   0.717608  0.763251\n",
       "ER2  0.981082  0.771704  0.976170   0.761905  0.781759\n",
       "ER3  0.986614  0.842250  0.980701   0.887283  0.801567\n",
       "ER4  0.997986  0.923463  0.989763   0.884615  0.965879\n",
       "ER5  0.998202  0.952000  0.995972   0.918919  0.987552\n",
       "ER6  0.984261  0.949153  0.995972   0.991150  0.910569\n",
       "L2   0.992232  0.944444  0.989596   0.951264  0.937722\n",
       "L4   0.996250  0.921409  0.995133   0.876289  0.971429\n",
       "M1   0.972699  0.719823  0.957543   0.743707  0.697425\n",
       "M2   0.986950  0.830224  0.969458   0.818015  0.842803\n",
       "M3   0.988631  0.823656  0.972479   0.862613  0.788066\n",
       "M4   0.988122  0.820000  0.975835   0.784689  0.858639\n",
       "M5   0.992024  0.832353  0.980869   0.827485  0.837278\n",
       "M6   0.993176  0.863962  0.990435   0.923469  0.811659\n",
       "MO2  0.980961  0.783099  0.987078   0.785311  0.780899\n",
       "PL2  0.998771  0.972789  0.998657   0.966216  0.979452\n",
       "PL3  1.000000  0.909091  0.999832   0.833333  1.000000\n",
       "PL4  0.998265  0.285714  0.998322   0.181818  0.666667\n",
       "U1   0.988931  0.912134  0.996476   0.923729  0.900826"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(multiclass)\n",
    "df.index = ['AUC','F1','Acc','Precision','Recall']\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a474aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import one_vs_rest_metrics, get_overall_multiclass_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "032d6a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auc</th>\n",
       "      <th>f1</th>\n",
       "      <th>n_true</th>\n",
       "      <th>n_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B1</th>\n",
       "      <td>0.990454</td>\n",
       "      <td>0.872928</td>\n",
       "      <td>85</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B2</th>\n",
       "      <td>0.918389</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E0</th>\n",
       "      <td>0.991074</td>\n",
       "      <td>0.937997</td>\n",
       "      <td>319</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E4</th>\n",
       "      <td>0.976843</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>67</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER1</th>\n",
       "      <td>0.988115</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>283</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER2</th>\n",
       "      <td>0.981082</td>\n",
       "      <td>0.771704</td>\n",
       "      <td>307</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER3</th>\n",
       "      <td>0.986614</td>\n",
       "      <td>0.842250</td>\n",
       "      <td>383</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER4</th>\n",
       "      <td>0.997986</td>\n",
       "      <td>0.923463</td>\n",
       "      <td>381</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER5</th>\n",
       "      <td>0.998202</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>241</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER6</th>\n",
       "      <td>0.984261</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>246</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L2</th>\n",
       "      <td>0.992232</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>562</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L4</th>\n",
       "      <td>0.996250</td>\n",
       "      <td>0.921409</td>\n",
       "      <td>175</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M1</th>\n",
       "      <td>0.972699</td>\n",
       "      <td>0.719823</td>\n",
       "      <td>466</td>\n",
       "      <td>437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M2</th>\n",
       "      <td>0.986950</td>\n",
       "      <td>0.830224</td>\n",
       "      <td>528</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M3</th>\n",
       "      <td>0.988631</td>\n",
       "      <td>0.823656</td>\n",
       "      <td>486</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M4</th>\n",
       "      <td>0.988122</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>382</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M5</th>\n",
       "      <td>0.992024</td>\n",
       "      <td>0.832353</td>\n",
       "      <td>338</td>\n",
       "      <td>342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M6</th>\n",
       "      <td>0.993176</td>\n",
       "      <td>0.863962</td>\n",
       "      <td>223</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MO2</th>\n",
       "      <td>0.980961</td>\n",
       "      <td>0.783099</td>\n",
       "      <td>178</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL2</th>\n",
       "      <td>0.998771</td>\n",
       "      <td>0.972789</td>\n",
       "      <td>146</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PL4</th>\n",
       "      <td>0.998265</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>U1</th>\n",
       "      <td>0.988931</td>\n",
       "      <td>0.912134</td>\n",
       "      <td>121</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          auc        f1  n_true  n_pred\n",
       "B1   0.990454  0.872928      85      96\n",
       "B2   0.918389  0.793103      34      24\n",
       "E0   0.991074  0.937997     319     310\n",
       "E4   0.976843  0.750000      67      77\n",
       "ER1  0.988115  0.739726     283     301\n",
       "ER2  0.981082  0.771704     307     315\n",
       "ER3  0.986614  0.842250     383     346\n",
       "ER4  0.997986  0.923463     381     416\n",
       "ER5  0.998202  0.952000     241     259\n",
       "ER6  0.984261  0.949153     246     226\n",
       "L2   0.992232  0.944444     562     554\n",
       "L4   0.996250  0.921409     175     194\n",
       "M1   0.972699  0.719823     466     437\n",
       "M2   0.986950  0.830224     528     544\n",
       "M3   0.988631  0.823656     486     444\n",
       "M4   0.988122  0.820000     382     418\n",
       "M5   0.992024  0.832353     338     342\n",
       "M6   0.993176  0.863962     223     196\n",
       "MO2  0.980961  0.783099     178     177\n",
       "PL2  0.998771  0.972789     146     148\n",
       "PL3  1.000000  0.909091       5       6\n",
       "PL4  0.998265  0.285714       3      11\n",
       "U1   0.988931  0.912134     121     118"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one_vs_rest = one_vs_rest_metrics(np.argmax(label.to_numpy(), axis=1),\n",
    "                    np.argmax(pred_class.to_numpy(), axis=1), \n",
    "                    pred_prob.to_numpy())\n",
    "df_one_vs_rest.index = cell_types_df['Cell_Types'].tolist()\n",
    "df_one_vs_rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62a951cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8531632824299379,\n",
       " 'balanced_accuracy': 0.8530460389601365,\n",
       " 'auc_ovr_macro': 0.9865231308846351,\n",
       " 'auc_ovr_weighted': 0.9880544259481447}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_overall_multiclass_metrics = get_overall_multiclass_metrics(np.argmax(label.to_numpy(), axis=1),\n",
    "                    np.argmax(pred_class.to_numpy(), axis=1), \n",
    "                    pred_prob.to_numpy())\n",
    "df_overall_multiclass_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
