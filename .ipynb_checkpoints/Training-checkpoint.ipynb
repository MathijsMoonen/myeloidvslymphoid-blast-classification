{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e66518e-71cb-4c3d-bccf-f85f17d8b732",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'segment_cell' from 'utils' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m### Internal Imports\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mResNext50\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Myresnext50\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_classification\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trainer_classification\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_optimizers\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mDatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDataLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Img_DataLoader\n",
      "File \u001b[1;32mD:\\Mathijs\\Open Universiteit\\Thesis\\Implementation\\DeepHeme_training\\train\\train_classification.py:10\u001b[0m\n\u001b[0;32m      8\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mDatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDataLoader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Img_DataLoader\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m configure_optimizers\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mtrainer_classification\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "File \u001b[1;32mD:\\Mathijs\\Open Universiteit\\Thesis\\Implementation\\DeepHeme_training\\Datasets\\DataLoader.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m segment_cell\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'segment_cell' from 'utils' (unknown location)"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import  glob\n",
    "import time\n",
    "import albumentations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from utils.utils import segment_cell\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder# creating instance of one-hot-encoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "### Internal Imports\n",
    "from models.ResNext50 import Myresnext50\n",
    "from train.train_classification import trainer_classification\n",
    "from utils.utils import configure_optimizers\n",
    "from Datasets.DataLoader import Img_DataLoader\n",
    "\n",
    "### PyTorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db7a2126-4878-4be8-a718-94250111828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import segment_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe32bca7-aab5-41df-afd9-98727f30a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data, split it into training and validation dataframes\n",
    "df = pd.read_pickle('imagepaths.pkl')\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.20, random_state=42, stratify=df['Label'])\n",
    "val_df, test_df = train_test_split(val_df, test_size=0.5, random_state=42, stratify=val_df['Label'])\n",
    "print(f\"Training set shape: {train_df.shape}          Training set label count: {str(Counter(train_df['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "print(f\"Validation set shape: {val_df.shape}         Validation set label count: {str(Counter(val_df['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "print(f\"Test set shape: {test_df.shape}         Validation set label count: {str(Counter(test_df['Label'].to_list()))[7:][1:][:-1]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49be3e84-3648-41d0-bd09-3ec7f9e0f754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes to check whether a model trained on no data indeed performs poorly, thus ensuring that there is no label leakage during evaluation\n",
    "\n",
    "# train_df_w, train_df_small = train_test_split(train_df, test_size=0.003, random_state=42, stratify=train_df['Label'])\n",
    "# val_df_w, val_df_small = train_test_split(val_df, test_size=0.05, random_state=42, stratify=val_df['Label'])\n",
    "# test_df_w, test_df_small = train_test_split(test_df, test_size=0.05, random_state=42, stratify=test_df['Label'])\n",
    "\n",
    "# print(f\"Training set shape: {train_df_small.shape}          Training set label count: {str(Counter(train_df_small['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "# print(f\"Validation set shape: {val_df_small.shape}         Validation set label count: {str(Counter(val_df_small['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "# print(f\"Test set shape: {test_df_small.shape}         Validation set label count: {str(Counter(test_df_small['Label'].to_list()))[7:][1:][:-1]} \\n\")\n",
    "\n",
    "# # Load df that represents the one hot encoding of each cell type (Myeloid, Lymphoid, other)\n",
    "# cell_types_df = pd.read_pickle(\"cell_types_df.pkl\")\n",
    "\n",
    "# # Load model\n",
    "# resnext50_pretrained = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\n",
    "# my_extended_model = Myresnext50(my_pretrained_model= resnext50_pretrained, num_classes = 3)\n",
    "\n",
    "# X_train_small = train_df_small['Filepath'].to_list()\n",
    "# X_val_small = val_df_small['Filepath'].to_list()\n",
    "\n",
    "# # Load labels\n",
    "# train_labels_small = train_df_small['Label'].to_list()\n",
    "# validation_labels_small = val_df_small['Label'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1fe00a-3ec1-4575-b1d1-6e81abc5f2b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load filepaths\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m X_train \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFilepath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[0;32m      3\u001b[0m X_val \u001b[38;5;241m=\u001b[39m val_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFilepath\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Load labels\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Load filepaths\n",
    "X_train = train_df['Filepath'].to_list()\n",
    "X_val = val_df['Filepath'].to_list()\n",
    "\n",
    "# Load labels\n",
    "train_labels = train_df['Label'].to_list()\n",
    "validation_labels = val_df['Label'].to_list()\n",
    "\n",
    "# Load df that represents the one hot encoding of each cell type (Myeloid, Lymphoid, other)\n",
    "cell_types_df = pd.read_pickle(\"cell_types_df.pkl\")\n",
    "\n",
    "# Load model\n",
    "resnext50_pretrained = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)\n",
    "my_extended_model = Myresnext50(my_pretrained_model= resnext50_pretrained, num_classes = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a3ea6b-a52c-4ac3-bd4d-de5aeab45789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple augumentation to improve the data generalibility\n",
    "\n",
    "transform_pipeline = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e317cbab-fa58-4e9e-ab1b-4d9ce018e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training setup\n",
    "trainer = trainer_classification(train_image_files=X_train, validation_image_files=X_val, train_labels=train_labels, validation_labels=validation_labels, model=my_extended_model,\n",
    "                                     img_transform=transform_pipeline, init_lr=0.001,\n",
    "                                     lr_decay_every_x_epochs=10,\n",
    "\n",
    "                                     weight_decay=0.0005, batch_size=32, epochs=30, gamma=0.1, df=cell_types_df,\n",
    "                                     save_checkpoints_dir='checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1e3c9e8-3c3a-41f4-bcf1-ee89be97997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For testing purposes\n",
    "\n",
    "# dataset = Img_DataLoader(img_list=X_train, labels=train_labels, split='train', transform = transform_pipeline, df = cell_types_df)\n",
    "# shuffle = True\n",
    "# dataloader = DataLoader(dataset, batch_size=32, num_workers=2, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39a05e49-861e-4464-b168-f9823ac383c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Create model\n",
      "==> List learnable parameters\n",
      "==> Load data\n",
      "16630\n",
      "2079\n",
      "==> Configure optimizer\n",
      "10\n",
      "==> Start training\n",
      "==> Create the saving dictionary\n",
      "The directory exists, overrode duplicate files\n",
      "==> Epoch: 1 Step: 50 LR: 0.001000 Total Loss: 0.1159 Runtime: 3.75 s/50 iters.\n",
      "==> Epoch: 1 Step: 100 LR: 0.001000 Total Loss: 0.1324 Runtime: 2.70 s/50 iters.\n",
      "==> Epoch: 1 Step: 150 LR: 0.001000 Total Loss: 0.1706 Runtime: 4.13 s/50 iters.\n",
      "==> Epoch: 1 Step: 200 LR: 0.001000 Total Loss: 0.0407 Runtime: 4.04 s/50 iters.\n",
      "==> Epoch: 1 Step: 250 LR: 0.001000 Total Loss: 0.0257 Runtime: 4.22 s/50 iters.\n",
      "==> Epoch: 1 Step: 300 LR: 0.001000 Total Loss: 0.1842 Runtime: 4.01 s/50 iters.\n",
      "==> Epoch: 1 Step: 350 LR: 0.001000 Total Loss: 0.0441 Runtime: 2.20 s/50 iters.\n",
      "==> Epoch: 1 Step: 400 LR: 0.001000 Total Loss: 0.1062 Runtime: 2.98 s/50 iters.\n",
      "==> Epoch: 1 Step: 450 LR: 0.001000 Total Loss: 0.1675 Runtime: 2.02 s/50 iters.\n",
      "==> Epoch: 1 Step: 500 LR: 0.001000 Total Loss: 0.0537 Runtime: 2.19 s/50 iters.\n",
      "==> Epoch: 1 Loss 0.206985 .\n",
      "==> Epoch: 2 Step: 550 LR: 0.000976 Total Loss: 0.0471 Runtime: 3.91 s/50 iters.\n",
      "==> Epoch: 2 Step: 600 LR: 0.000976 Total Loss: 0.0223 Runtime: 6.42 s/50 iters.\n",
      "==> Epoch: 2 Step: 650 LR: 0.000976 Total Loss: 0.0653 Runtime: 6.52 s/50 iters.\n",
      "==> Epoch: 2 Step: 700 LR: 0.000976 Total Loss: 0.0460 Runtime: 6.67 s/50 iters.\n",
      "==> Epoch: 2 Step: 750 LR: 0.000976 Total Loss: 0.1302 Runtime: 6.62 s/50 iters.\n",
      "==> Epoch: 2 Step: 800 LR: 0.000976 Total Loss: 0.0642 Runtime: 6.78 s/50 iters.\n",
      "==> Epoch: 2 Step: 850 LR: 0.000976 Total Loss: 0.1412 Runtime: 6.87 s/50 iters.\n",
      "==> Epoch: 2 Step: 900 LR: 0.000976 Total Loss: 0.0213 Runtime: 6.80 s/50 iters.\n",
      "==> Epoch: 2 Step: 950 LR: 0.000976 Total Loss: 0.0608 Runtime: 6.69 s/50 iters.\n",
      "==> Epoch: 2 Step: 1000 LR: 0.000976 Total Loss: 0.0127 Runtime: 6.72 s/50 iters.\n",
      "==> Epoch: 2 Loss 0.090424 .\n",
      "==> Epoch: 3 Step: 1050 LR: 0.000905 Total Loss: 0.1118 Runtime: 1.29 s/50 iters.\n",
      "==> Epoch: 3 Step: 1100 LR: 0.000905 Total Loss: 0.0244 Runtime: 6.39 s/50 iters.\n",
      "==> Epoch: 3 Step: 1150 LR: 0.000905 Total Loss: 0.0082 Runtime: 6.76 s/50 iters.\n",
      "==> Epoch: 3 Step: 1200 LR: 0.000905 Total Loss: 0.0393 Runtime: 6.80 s/50 iters.\n",
      "==> Epoch: 3 Step: 1250 LR: 0.000905 Total Loss: 0.0202 Runtime: 6.74 s/50 iters.\n",
      "==> Epoch: 3 Step: 1300 LR: 0.000905 Total Loss: 0.1202 Runtime: 6.74 s/50 iters.\n",
      "==> Epoch: 3 Step: 1350 LR: 0.000905 Total Loss: 0.0486 Runtime: 6.64 s/50 iters.\n",
      "==> Epoch: 3 Step: 1400 LR: 0.000905 Total Loss: 0.0931 Runtime: 6.64 s/50 iters.\n",
      "==> Epoch: 3 Step: 1450 LR: 0.000905 Total Loss: 0.0663 Runtime: 6.66 s/50 iters.\n",
      "==> Epoch: 3 Step: 1500 LR: 0.000905 Total Loss: 0.2315 Runtime: 6.62 s/50 iters.\n",
      "==> Epoch: 3 Step: 1550 LR: 0.000905 Total Loss: 0.0285 Runtime: 6.77 s/50 iters.\n",
      "==> Epoch: 3 Loss 2.897588 .\n",
      "==> Epoch: 4 Step: 1600 LR: 0.000794 Total Loss: 0.0547 Runtime: 5.30 s/50 iters.\n",
      "==> Epoch: 4 Step: 1650 LR: 0.000794 Total Loss: 0.2696 Runtime: 6.46 s/50 iters.\n",
      "==> Epoch: 4 Step: 1700 LR: 0.000794 Total Loss: 0.1346 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 4 Step: 1750 LR: 0.000794 Total Loss: 0.1124 Runtime: 6.69 s/50 iters.\n",
      "==> Epoch: 4 Step: 1800 LR: 0.000794 Total Loss: 0.0220 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 4 Step: 1850 LR: 0.000794 Total Loss: 0.0118 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 4 Step: 1900 LR: 0.000794 Total Loss: 0.1677 Runtime: 6.62 s/50 iters.\n",
      "==> Epoch: 4 Step: 1950 LR: 0.000794 Total Loss: 0.0373 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 4 Step: 2000 LR: 0.000794 Total Loss: 0.1141 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 4 Step: 2050 LR: 0.000794 Total Loss: 0.0233 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 4 Loss 0.280526 .\n",
      "==> Epoch: 5 Step: 2100 LR: 0.000655 Total Loss: 0.0207 Runtime: 2.55 s/50 iters.\n",
      "==> Epoch: 5 Step: 2150 LR: 0.000655 Total Loss: 0.1420 Runtime: 6.41 s/50 iters.\n",
      "==> Epoch: 5 Step: 2200 LR: 0.000655 Total Loss: 0.0375 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 5 Step: 2250 LR: 0.000655 Total Loss: 0.0908 Runtime: 6.59 s/50 iters.\n",
      "==> Epoch: 5 Step: 2300 LR: 0.000655 Total Loss: 0.0921 Runtime: 6.59 s/50 iters.\n",
      "==> Epoch: 5 Step: 2350 LR: 0.000655 Total Loss: 0.0092 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 5 Step: 2400 LR: 0.000655 Total Loss: 0.2128 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 5 Step: 2450 LR: 0.000655 Total Loss: 0.1845 Runtime: 6.67 s/50 iters.\n",
      "==> Epoch: 5 Step: 2500 LR: 0.000655 Total Loss: 0.0418 Runtime: 6.66 s/50 iters.\n",
      "==> Epoch: 5 Step: 2550 LR: 0.000655 Total Loss: 0.1579 Runtime: 6.62 s/50 iters.\n",
      "==> Epoch: 5 Step: 2600 LR: 0.000655 Total Loss: 0.1706 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 5 Loss 0.103510 .\n",
      "==> Epoch: 6 Step: 2650 LR: 0.000500 Total Loss: 0.0505 Runtime: 6.45 s/50 iters.\n",
      "==> Epoch: 6 Step: 2700 LR: 0.000500 Total Loss: 0.0227 Runtime: 6.69 s/50 iters.\n",
      "==> Epoch: 6 Step: 2750 LR: 0.000500 Total Loss: 0.0632 Runtime: 9.56 s/50 iters.\n",
      "==> Epoch: 6 Step: 2800 LR: 0.000500 Total Loss: 0.0362 Runtime: 9.50 s/50 iters.\n",
      "==> Epoch: 6 Step: 2850 LR: 0.000500 Total Loss: 0.1337 Runtime: 6.66 s/50 iters.\n",
      "==> Epoch: 6 Step: 2900 LR: 0.000500 Total Loss: 0.1721 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 6 Step: 2950 LR: 0.000500 Total Loss: 0.0279 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 6 Step: 3000 LR: 0.000500 Total Loss: 0.0440 Runtime: 6.86 s/50 iters.\n",
      "==> Epoch: 6 Step: 3050 LR: 0.000500 Total Loss: 0.1542 Runtime: 6.59 s/50 iters.\n",
      "==> Epoch: 6 Step: 3100 LR: 0.000500 Total Loss: 0.1427 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 6 Loss 0.175636 .\n",
      "==> Epoch: 7 Step: 3150 LR: 0.000345 Total Loss: 0.0171 Runtime: 4.03 s/50 iters.\n",
      "==> Epoch: 7 Step: 3200 LR: 0.000345 Total Loss: 0.0074 Runtime: 6.71 s/50 iters.\n",
      "==> Epoch: 7 Step: 3250 LR: 0.000345 Total Loss: 0.0118 Runtime: 7.22 s/50 iters.\n",
      "==> Epoch: 7 Step: 3300 LR: 0.000345 Total Loss: 0.0143 Runtime: 6.68 s/50 iters.\n",
      "==> Epoch: 7 Step: 3350 LR: 0.000345 Total Loss: 0.0618 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 7 Step: 3400 LR: 0.000345 Total Loss: 0.0077 Runtime: 6.59 s/50 iters.\n",
      "==> Epoch: 7 Step: 3450 LR: 0.000345 Total Loss: 0.0046 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 7 Step: 3500 LR: 0.000345 Total Loss: 0.1847 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 7 Step: 3550 LR: 0.000345 Total Loss: 0.0740 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 7 Step: 3600 LR: 0.000345 Total Loss: 0.0842 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 7 Loss 0.059723 .\n",
      "==> Epoch: 8 Step: 3650 LR: 0.000206 Total Loss: 0.0386 Runtime: 1.25 s/50 iters.\n",
      "==> Epoch: 8 Step: 3700 LR: 0.000206 Total Loss: 0.0121 Runtime: 6.36 s/50 iters.\n",
      "==> Epoch: 8 Step: 3750 LR: 0.000206 Total Loss: 0.0119 Runtime: 6.52 s/50 iters.\n",
      "==> Epoch: 8 Step: 3800 LR: 0.000206 Total Loss: 0.0124 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 8 Step: 3850 LR: 0.000206 Total Loss: 0.0048 Runtime: 6.66 s/50 iters.\n",
      "==> Epoch: 8 Step: 3900 LR: 0.000206 Total Loss: 0.0091 Runtime: 6.72 s/50 iters.\n",
      "==> Epoch: 8 Step: 3950 LR: 0.000206 Total Loss: 0.1993 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 8 Step: 4000 LR: 0.000206 Total Loss: 0.0868 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 8 Step: 4050 LR: 0.000206 Total Loss: 0.1192 Runtime: 6.65 s/50 iters.\n",
      "==> Epoch: 8 Step: 4100 LR: 0.000206 Total Loss: 0.0195 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 8 Step: 4150 LR: 0.000206 Total Loss: 0.0212 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 8 Loss 0.090783 .\n",
      "==> Epoch: 9 Step: 4200 LR: 0.000095 Total Loss: 0.0216 Runtime: 5.13 s/50 iters.\n",
      "==> Epoch: 9 Step: 4250 LR: 0.000095 Total Loss: 0.1349 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 9 Step: 4300 LR: 0.000095 Total Loss: 0.0102 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 9 Step: 4350 LR: 0.000095 Total Loss: 0.0065 Runtime: 6.68 s/50 iters.\n",
      "==> Epoch: 9 Step: 4400 LR: 0.000095 Total Loss: 0.0081 Runtime: 6.68 s/50 iters.\n",
      "==> Epoch: 9 Step: 4450 LR: 0.000095 Total Loss: 0.0091 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 9 Step: 4500 LR: 0.000095 Total Loss: 0.0080 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 9 Step: 4550 LR: 0.000095 Total Loss: 0.0067 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 9 Step: 4600 LR: 0.000095 Total Loss: 0.0153 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 9 Step: 4650 LR: 0.000095 Total Loss: 0.0078 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 9 Loss 0.057987 .\n",
      "==> Epoch: 10 Step: 4700 LR: 0.000024 Total Loss: 0.1123 Runtime: 2.54 s/50 iters.\n",
      "==> Epoch: 10 Step: 4750 LR: 0.000024 Total Loss: 0.2709 Runtime: 6.44 s/50 iters.\n",
      "==> Epoch: 10 Step: 4800 LR: 0.000024 Total Loss: 0.0330 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 10 Step: 4850 LR: 0.000024 Total Loss: 0.1135 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 10 Step: 4900 LR: 0.000024 Total Loss: 0.0066 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 10 Step: 4950 LR: 0.000024 Total Loss: 0.0023 Runtime: 6.65 s/50 iters.\n",
      "==> Epoch: 10 Step: 5000 LR: 0.000024 Total Loss: 0.0092 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 10 Step: 5050 LR: 0.000024 Total Loss: 0.0056 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 10 Step: 5100 LR: 0.000024 Total Loss: 0.0034 Runtime: 6.63 s/50 iters.\n",
      "==> Epoch: 10 Step: 5150 LR: 0.000024 Total Loss: 0.0400 Runtime: 6.62 s/50 iters.\n",
      "==> Epoch: 10 Step: 5200 LR: 0.000024 Total Loss: 0.0018 Runtime: 6.64 s/50 iters.\n",
      "==> Epoch: 10 Loss 0.049448 .\n",
      "==> Epoch: 11 Step: 5250 LR: 0.000000 Total Loss: 0.0032 Runtime: 6.40 s/50 iters.\n",
      "==> Epoch: 11 Step: 5300 LR: 0.000000 Total Loss: 0.0042 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 11 Step: 5350 LR: 0.000000 Total Loss: 0.0027 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 11 Step: 5400 LR: 0.000000 Total Loss: 0.0149 Runtime: 6.66 s/50 iters.\n",
      "==> Epoch: 11 Step: 5450 LR: 0.000000 Total Loss: 0.0070 Runtime: 6.76 s/50 iters.\n",
      "==> Epoch: 11 Step: 5500 LR: 0.000000 Total Loss: 0.0316 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 11 Step: 5550 LR: 0.000000 Total Loss: 0.0212 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 11 Step: 5600 LR: 0.000000 Total Loss: 0.0040 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 11 Step: 5650 LR: 0.000000 Total Loss: 0.0038 Runtime: 6.64 s/50 iters.\n",
      "==> Epoch: 11 Step: 5700 LR: 0.000000 Total Loss: 0.0174 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 11 Loss 0.049584 .\n",
      "==> Epoch: 12 Step: 5750 LR: 0.000024 Total Loss: 0.0034 Runtime: 3.84 s/50 iters.\n",
      "==> Epoch: 12 Step: 5800 LR: 0.000024 Total Loss: 0.0088 Runtime: 6.44 s/50 iters.\n",
      "==> Epoch: 12 Step: 5850 LR: 0.000024 Total Loss: 0.0159 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 12 Step: 5900 LR: 0.000024 Total Loss: 0.0150 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 12 Step: 5950 LR: 0.000024 Total Loss: 0.0968 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 12 Step: 6000 LR: 0.000024 Total Loss: 0.0044 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 12 Step: 6050 LR: 0.000024 Total Loss: 0.0472 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 12 Step: 6100 LR: 0.000024 Total Loss: 0.0082 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 12 Step: 6150 LR: 0.000024 Total Loss: 0.1091 Runtime: 6.59 s/50 iters.\n",
      "==> Epoch: 12 Step: 6200 LR: 0.000024 Total Loss: 0.0036 Runtime: 6.64 s/50 iters.\n",
      "==> Epoch: 12 Loss 0.048218 .\n",
      "==> Epoch: 13 Step: 6250 LR: 0.000095 Total Loss: 0.0014 Runtime: 1.26 s/50 iters.\n",
      "==> Epoch: 13 Step: 6300 LR: 0.000095 Total Loss: 0.0015 Runtime: 6.37 s/50 iters.\n",
      "==> Epoch: 13 Step: 6350 LR: 0.000095 Total Loss: 0.0057 Runtime: 6.63 s/50 iters.\n",
      "==> Epoch: 13 Step: 6400 LR: 0.000095 Total Loss: 0.0021 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 13 Step: 6450 LR: 0.000095 Total Loss: 0.0086 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 13 Step: 6500 LR: 0.000095 Total Loss: 0.0101 Runtime: 6.64 s/50 iters.\n",
      "==> Epoch: 13 Step: 6550 LR: 0.000095 Total Loss: 0.0041 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 13 Step: 6600 LR: 0.000095 Total Loss: 0.0046 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 13 Step: 6650 LR: 0.000095 Total Loss: 0.1015 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 13 Step: 6700 LR: 0.000095 Total Loss: 0.0173 Runtime: 6.59 s/50 iters.\n",
      "==> Epoch: 13 Step: 6750 LR: 0.000095 Total Loss: 0.0076 Runtime: 6.67 s/50 iters.\n",
      "==> Epoch: 13 Loss 0.052427 .\n",
      "==> Epoch: 14 Step: 6800 LR: 0.000206 Total Loss: 0.0347 Runtime: 5.09 s/50 iters.\n",
      "==> Epoch: 14 Step: 6850 LR: 0.000206 Total Loss: 0.0029 Runtime: 6.46 s/50 iters.\n",
      "==> Epoch: 14 Step: 6900 LR: 0.000206 Total Loss: 0.1157 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 14 Step: 6950 LR: 0.000206 Total Loss: 0.0213 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 14 Step: 7000 LR: 0.000206 Total Loss: 0.0038 Runtime: 6.64 s/50 iters.\n",
      "==> Epoch: 14 Step: 7050 LR: 0.000206 Total Loss: 0.1175 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 14 Step: 7100 LR: 0.000206 Total Loss: 0.0171 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 14 Step: 7150 LR: 0.000206 Total Loss: 0.0052 Runtime: 6.62 s/50 iters.\n",
      "==> Epoch: 14 Step: 7200 LR: 0.000206 Total Loss: 0.0122 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 14 Step: 7250 LR: 0.000206 Total Loss: 0.0107 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 14 Loss 0.061305 .\n",
      "==> Epoch: 15 Step: 7300 LR: 0.000345 Total Loss: 0.0077 Runtime: 2.53 s/50 iters.\n",
      "==> Epoch: 15 Step: 7350 LR: 0.000345 Total Loss: 0.0338 Runtime: 6.43 s/50 iters.\n",
      "==> Epoch: 15 Step: 7400 LR: 0.000345 Total Loss: 0.0926 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 15 Step: 7450 LR: 0.000345 Total Loss: 0.0224 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 15 Step: 7500 LR: 0.000345 Total Loss: 0.0976 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 15 Step: 7550 LR: 0.000345 Total Loss: 0.0223 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 15 Step: 7600 LR: 0.000345 Total Loss: 0.0487 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 15 Step: 7650 LR: 0.000345 Total Loss: 0.0196 Runtime: 6.59 s/50 iters.\n",
      "==> Epoch: 15 Step: 7700 LR: 0.000345 Total Loss: 0.1193 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 15 Step: 7750 LR: 0.000345 Total Loss: 0.1469 Runtime: 6.64 s/50 iters.\n",
      "==> Epoch: 15 Step: 7800 LR: 0.000345 Total Loss: 0.0026 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 15 Loss 0.094954 .\n",
      "==> Epoch: 16 Step: 7850 LR: 0.000500 Total Loss: 0.0106 Runtime: 6.41 s/50 iters.\n",
      "==> Epoch: 16 Step: 7900 LR: 0.000500 Total Loss: 0.1572 Runtime: 6.52 s/50 iters.\n",
      "==> Epoch: 16 Step: 7950 LR: 0.000500 Total Loss: 0.0091 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 16 Step: 8000 LR: 0.000500 Total Loss: 0.0413 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 16 Step: 8050 LR: 0.000500 Total Loss: 0.0168 Runtime: 6.64 s/50 iters.\n",
      "==> Epoch: 16 Step: 8100 LR: 0.000500 Total Loss: 0.0412 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 16 Step: 8150 LR: 0.000500 Total Loss: 0.0316 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 16 Step: 8200 LR: 0.000500 Total Loss: 0.0323 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 16 Step: 8250 LR: 0.000500 Total Loss: 0.0384 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 16 Step: 8300 LR: 0.000500 Total Loss: 0.0188 Runtime: 6.67 s/50 iters.\n",
      "==> Epoch: 16 Loss 0.074069 .\n",
      "==> Epoch: 17 Step: 8350 LR: 0.000655 Total Loss: 0.1504 Runtime: 3.81 s/50 iters.\n",
      "==> Epoch: 17 Step: 8400 LR: 0.000655 Total Loss: 0.0519 Runtime: 6.40 s/50 iters.\n",
      "==> Epoch: 17 Step: 8450 LR: 0.000655 Total Loss: 0.0721 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 17 Step: 8500 LR: 0.000655 Total Loss: 0.0540 Runtime: 6.63 s/50 iters.\n",
      "==> Epoch: 17 Step: 8550 LR: 0.000655 Total Loss: 0.1463 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 17 Step: 8600 LR: 0.000655 Total Loss: 0.1893 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 17 Step: 8650 LR: 0.000655 Total Loss: 0.0154 Runtime: 6.59 s/50 iters.\n",
      "==> Epoch: 17 Step: 8700 LR: 0.000655 Total Loss: 0.0028 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 17 Step: 8750 LR: 0.000655 Total Loss: 0.0159 Runtime: 6.60 s/50 iters.\n",
      "==> Epoch: 17 Step: 8800 LR: 0.000655 Total Loss: 0.0176 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 17 Loss 0.069158 .\n",
      "==> Epoch: 18 Step: 8850 LR: 0.000794 Total Loss: 0.0217 Runtime: 1.25 s/50 iters.\n",
      "==> Epoch: 18 Step: 8900 LR: 0.000794 Total Loss: 0.0170 Runtime: 6.36 s/50 iters.\n",
      "==> Epoch: 18 Step: 8950 LR: 0.000794 Total Loss: 0.0208 Runtime: 6.49 s/50 iters.\n",
      "==> Epoch: 18 Step: 9000 LR: 0.000794 Total Loss: 0.0804 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 18 Step: 9050 LR: 0.000794 Total Loss: 0.0802 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 18 Step: 9100 LR: 0.000794 Total Loss: 0.0346 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 18 Step: 9150 LR: 0.000794 Total Loss: 0.1808 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 18 Step: 9200 LR: 0.000794 Total Loss: 0.0203 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 18 Step: 9250 LR: 0.000794 Total Loss: 0.0994 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 18 Step: 9300 LR: 0.000794 Total Loss: 0.2844 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 18 Step: 9350 LR: 0.000794 Total Loss: 0.0544 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 18 Loss 0.080762 .\n",
      "==> Epoch: 19 Step: 9400 LR: 0.000905 Total Loss: 0.1136 Runtime: 5.12 s/50 iters.\n",
      "==> Epoch: 19 Step: 9450 LR: 0.000905 Total Loss: 0.0034 Runtime: 6.49 s/50 iters.\n",
      "==> Epoch: 19 Step: 9500 LR: 0.000905 Total Loss: 0.0090 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 19 Step: 9550 LR: 0.000905 Total Loss: 0.0352 Runtime: 6.52 s/50 iters.\n",
      "==> Epoch: 19 Step: 9600 LR: 0.000905 Total Loss: 0.0349 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 19 Step: 9650 LR: 0.000905 Total Loss: 0.0641 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 19 Step: 9700 LR: 0.000905 Total Loss: 0.0150 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 19 Step: 9750 LR: 0.000905 Total Loss: 0.0156 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 19 Step: 9800 LR: 0.000905 Total Loss: 0.0886 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 19 Step: 9850 LR: 0.000905 Total Loss: 0.0463 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 19 Loss 0.085634 .\n",
      "==> Epoch: 20 Step: 9900 LR: 0.000976 Total Loss: 0.0567 Runtime: 2.54 s/50 iters.\n",
      "==> Epoch: 20 Step: 9950 LR: 0.000976 Total Loss: 0.0342 Runtime: 6.36 s/50 iters.\n",
      "==> Epoch: 20 Step: 10000 LR: 0.000976 Total Loss: 0.0193 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 20 Step: 10050 LR: 0.000976 Total Loss: 0.0151 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 20 Step: 10100 LR: 0.000976 Total Loss: 0.2686 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 20 Step: 10150 LR: 0.000976 Total Loss: 0.0125 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 20 Step: 10200 LR: 0.000976 Total Loss: 0.0674 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 20 Step: 10250 LR: 0.000976 Total Loss: 0.0515 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 20 Step: 10300 LR: 0.000976 Total Loss: 0.0589 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 20 Step: 10350 LR: 0.000976 Total Loss: 0.0938 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 20 Step: 10400 LR: 0.000976 Total Loss: 0.0049 Runtime: 6.49 s/50 iters.\n",
      "==> Epoch: 20 Loss 0.094861 .\n",
      "==> Epoch: 21 Step: 10450 LR: 0.001000 Total Loss: 0.0107 Runtime: 6.37 s/50 iters.\n",
      "==> Epoch: 21 Step: 10500 LR: 0.001000 Total Loss: 0.1739 Runtime: 6.43 s/50 iters.\n",
      "==> Epoch: 21 Step: 10550 LR: 0.001000 Total Loss: 0.0748 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 21 Step: 10600 LR: 0.001000 Total Loss: 0.0136 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 21 Step: 10650 LR: 0.001000 Total Loss: 0.0417 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 21 Step: 10700 LR: 0.001000 Total Loss: 0.0080 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 21 Step: 10750 LR: 0.001000 Total Loss: 0.1075 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 21 Step: 10800 LR: 0.001000 Total Loss: 0.1153 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 21 Step: 10850 LR: 0.001000 Total Loss: 0.0620 Runtime: 6.55 s/50 iters.\n",
      "==> Epoch: 21 Step: 10900 LR: 0.001000 Total Loss: 0.0493 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 21 Loss 0.161053 .\n",
      "==> Epoch: 22 Step: 10950 LR: 0.000976 Total Loss: 0.0786 Runtime: 3.80 s/50 iters.\n",
      "==> Epoch: 22 Step: 11000 LR: 0.000976 Total Loss: 0.2493 Runtime: 6.41 s/50 iters.\n",
      "==> Epoch: 22 Step: 11050 LR: 0.000976 Total Loss: 0.1633 Runtime: 6.59 s/50 iters.\n",
      "==> Epoch: 22 Step: 11100 LR: 0.000976 Total Loss: 0.2087 Runtime: 6.50 s/50 iters.\n",
      "==> Epoch: 22 Step: 11150 LR: 0.000976 Total Loss: 0.0927 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 22 Step: 11200 LR: 0.000976 Total Loss: 0.0206 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 22 Step: 11250 LR: 0.000976 Total Loss: 0.0146 Runtime: 6.50 s/50 iters.\n",
      "==> Epoch: 22 Step: 11300 LR: 0.000976 Total Loss: 0.0054 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 22 Step: 11350 LR: 0.000976 Total Loss: 0.0048 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 22 Step: 11400 LR: 0.000976 Total Loss: 0.0093 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 22 Loss 0.113880 .\n",
      "==> Epoch: 23 Step: 11450 LR: 0.000905 Total Loss: 0.0253 Runtime: 1.25 s/50 iters.\n",
      "==> Epoch: 23 Step: 11500 LR: 0.000905 Total Loss: 0.0564 Runtime: 6.33 s/50 iters.\n",
      "==> Epoch: 23 Step: 11550 LR: 0.000905 Total Loss: 0.0545 Runtime: 6.50 s/50 iters.\n",
      "==> Epoch: 23 Step: 11600 LR: 0.000905 Total Loss: 0.0087 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 23 Step: 11650 LR: 0.000905 Total Loss: 0.0177 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 23 Step: 11700 LR: 0.000905 Total Loss: 0.0133 Runtime: 6.52 s/50 iters.\n",
      "==> Epoch: 23 Step: 11750 LR: 0.000905 Total Loss: 0.0219 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 23 Step: 11800 LR: 0.000905 Total Loss: 0.0164 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 23 Step: 11850 LR: 0.000905 Total Loss: 0.0055 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 23 Step: 11900 LR: 0.000905 Total Loss: 0.0137 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 23 Step: 11950 LR: 0.000905 Total Loss: 0.1415 Runtime: 6.49 s/50 iters.\n",
      "==> Epoch: 23 Loss 0.063036 .\n",
      "==> Epoch: 24 Step: 12000 LR: 0.000794 Total Loss: 0.0139 Runtime: 5.08 s/50 iters.\n",
      "==> Epoch: 24 Step: 12050 LR: 0.000794 Total Loss: 0.0110 Runtime: 6.40 s/50 iters.\n",
      "==> Epoch: 24 Step: 12100 LR: 0.000794 Total Loss: 0.0105 Runtime: 6.52 s/50 iters.\n",
      "==> Epoch: 24 Step: 12150 LR: 0.000794 Total Loss: 0.0115 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 24 Step: 12200 LR: 0.000794 Total Loss: 0.1771 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 24 Step: 12250 LR: 0.000794 Total Loss: 0.0147 Runtime: 6.51 s/50 iters.\n",
      "==> Epoch: 24 Step: 12300 LR: 0.000794 Total Loss: 0.0185 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 24 Step: 12350 LR: 0.000794 Total Loss: 0.1051 Runtime: 6.56 s/50 iters.\n",
      "==> Epoch: 24 Step: 12400 LR: 0.000794 Total Loss: 0.0364 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 24 Step: 12450 LR: 0.000794 Total Loss: 0.0083 Runtime: 6.53 s/50 iters.\n",
      "==> Epoch: 24 Loss 0.137663 .\n",
      "==> Epoch: 25 Step: 12500 LR: 0.000655 Total Loss: 0.0216 Runtime: 2.53 s/50 iters.\n",
      "==> Epoch: 25 Step: 12550 LR: 0.000655 Total Loss: 0.0059 Runtime: 6.32 s/50 iters.\n",
      "==> Epoch: 25 Step: 12600 LR: 0.000655 Total Loss: 0.0185 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 25 Step: 12650 LR: 0.000655 Total Loss: 0.0699 Runtime: 7.21 s/50 iters.\n",
      "==> Epoch: 25 Step: 12700 LR: 0.000655 Total Loss: 0.0212 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 25 Step: 12750 LR: 0.000655 Total Loss: 0.1027 Runtime: 6.61 s/50 iters.\n",
      "==> Epoch: 25 Step: 12800 LR: 0.000655 Total Loss: 0.0109 Runtime: 6.58 s/50 iters.\n",
      "==> Epoch: 25 Step: 12850 LR: 0.000655 Total Loss: 0.0057 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 25 Step: 12900 LR: 0.000655 Total Loss: 0.1626 Runtime: 6.95 s/50 iters.\n",
      "==> Epoch: 25 Step: 12950 LR: 0.000655 Total Loss: 0.0587 Runtime: 7.13 s/50 iters.\n",
      "==> Epoch: 25 Step: 13000 LR: 0.000655 Total Loss: 0.0028 Runtime: 7.11 s/50 iters.\n",
      "==> Epoch: 25 Loss 0.062986 .\n",
      "==> Epoch: 26 Step: 13050 LR: 0.000500 Total Loss: 0.0185 Runtime: 7.61 s/50 iters.\n",
      "==> Epoch: 26 Step: 13100 LR: 0.000500 Total Loss: 0.0366 Runtime: 6.93 s/50 iters.\n",
      "==> Epoch: 26 Step: 13150 LR: 0.000500 Total Loss: 0.0057 Runtime: 7.45 s/50 iters.\n",
      "==> Epoch: 26 Step: 13200 LR: 0.000500 Total Loss: 0.0114 Runtime: 6.85 s/50 iters.\n",
      "==> Epoch: 26 Step: 13250 LR: 0.000500 Total Loss: 0.0046 Runtime: 6.85 s/50 iters.\n",
      "==> Epoch: 26 Step: 13300 LR: 0.000500 Total Loss: 0.0176 Runtime: 7.11 s/50 iters.\n",
      "==> Epoch: 26 Step: 13350 LR: 0.000500 Total Loss: 0.2656 Runtime: 6.84 s/50 iters.\n",
      "==> Epoch: 26 Step: 13400 LR: 0.000500 Total Loss: 0.0063 Runtime: 6.59 s/50 iters.\n",
      "==> Epoch: 26 Step: 13450 LR: 0.000500 Total Loss: 0.0224 Runtime: 6.78 s/50 iters.\n",
      "==> Epoch: 26 Step: 13500 LR: 0.000500 Total Loss: 0.0286 Runtime: 6.63 s/50 iters.\n",
      "==> Epoch: 26 Loss 0.061639 .\n",
      "==> Epoch: 27 Step: 13550 LR: 0.000345 Total Loss: 0.0606 Runtime: 3.92 s/50 iters.\n",
      "==> Epoch: 27 Step: 13600 LR: 0.000345 Total Loss: 0.1612 Runtime: 6.45 s/50 iters.\n",
      "==> Epoch: 27 Step: 13650 LR: 0.000345 Total Loss: 0.0094 Runtime: 6.49 s/50 iters.\n",
      "==> Epoch: 27 Step: 13700 LR: 0.000345 Total Loss: 0.0734 Runtime: 6.54 s/50 iters.\n",
      "==> Epoch: 27 Step: 13750 LR: 0.000345 Total Loss: 0.1127 Runtime: 6.57 s/50 iters.\n",
      "==> Epoch: 27 Step: 13800 LR: 0.000345 Total Loss: 0.0617 Runtime: 7.01 s/50 iters.\n",
      "==> Epoch: 27 Step: 13850 LR: 0.000345 Total Loss: 0.0061 Runtime: 7.03 s/50 iters.\n",
      "==> Epoch: 27 Step: 13900 LR: 0.000345 Total Loss: 0.1000 Runtime: 6.85 s/50 iters.\n",
      "==> Epoch: 27 Step: 13950 LR: 0.000345 Total Loss: 0.0534 Runtime: 6.59 s/50 iters.\n",
      "==> Epoch: 27 Step: 14000 LR: 0.000345 Total Loss: 0.0049 Runtime: 6.82 s/50 iters.\n",
      "==> Epoch: 27 Loss 0.058504 .\n",
      "==> Epoch: 28 Step: 14050 LR: 0.000206 Total Loss: 0.0766 Runtime: 1.32 s/50 iters.\n",
      "==> Epoch: 28 Step: 14100 LR: 0.000206 Total Loss: 0.0149 Runtime: 6.77 s/50 iters.\n",
      "==> Epoch: 28 Step: 14150 LR: 0.000206 Total Loss: 0.2045 Runtime: 6.95 s/50 iters.\n",
      "==> Epoch: 28 Step: 14200 LR: 0.000206 Total Loss: 0.0029 Runtime: 8.19 s/50 iters.\n",
      "==> Epoch: 28 Step: 14250 LR: 0.000206 Total Loss: 0.0492 Runtime: 10.30 s/50 iters.\n",
      "==> Epoch: 28 Step: 14300 LR: 0.000206 Total Loss: 0.1285 Runtime: 10.19 s/50 iters.\n",
      "==> Epoch: 28 Step: 14350 LR: 0.000206 Total Loss: 0.0953 Runtime: 8.83 s/50 iters.\n",
      "==> Epoch: 28 Step: 14400 LR: 0.000206 Total Loss: 0.0086 Runtime: 8.53 s/50 iters.\n",
      "==> Epoch: 28 Step: 14450 LR: 0.000206 Total Loss: 0.0099 Runtime: 8.64 s/50 iters.\n",
      "==> Epoch: 28 Step: 14500 LR: 0.000206 Total Loss: 0.1330 Runtime: 8.71 s/50 iters.\n",
      "==> Epoch: 28 Step: 14550 LR: 0.000206 Total Loss: 0.0021 Runtime: 8.72 s/50 iters.\n",
      "==> Epoch: 28 Loss 0.046510 .\n",
      "==> Epoch: 29 Step: 14600 LR: 0.000095 Total Loss: 0.1019 Runtime: 7.01 s/50 iters.\n",
      "==> Epoch: 29 Step: 14650 LR: 0.000095 Total Loss: 0.0213 Runtime: 8.72 s/50 iters.\n",
      "==> Epoch: 29 Step: 14700 LR: 0.000095 Total Loss: 0.0376 Runtime: 8.55 s/50 iters.\n",
      "==> Epoch: 29 Step: 14750 LR: 0.000095 Total Loss: 0.0101 Runtime: 8.95 s/50 iters.\n",
      "==> Epoch: 29 Step: 14800 LR: 0.000095 Total Loss: 0.0114 Runtime: 8.92 s/50 iters.\n",
      "==> Epoch: 29 Step: 14850 LR: 0.000095 Total Loss: 0.0267 Runtime: 8.59 s/50 iters.\n",
      "==> Epoch: 29 Step: 14900 LR: 0.000095 Total Loss: 0.0056 Runtime: 8.52 s/50 iters.\n",
      "==> Epoch: 29 Step: 14950 LR: 0.000095 Total Loss: 0.0232 Runtime: 8.74 s/50 iters.\n",
      "==> Epoch: 29 Step: 15000 LR: 0.000095 Total Loss: 0.0071 Runtime: 8.99 s/50 iters.\n",
      "==> Epoch: 29 Step: 15050 LR: 0.000095 Total Loss: 0.0056 Runtime: 8.74 s/50 iters.\n",
      "==> Epoch: 29 Loss 0.045329 .\n",
      "==> Epoch: 30 Step: 15100 LR: 0.000024 Total Loss: 0.1030 Runtime: 3.33 s/50 iters.\n",
      "==> Epoch: 30 Step: 15150 LR: 0.000024 Total Loss: 0.0022 Runtime: 8.63 s/50 iters.\n",
      "==> Epoch: 30 Step: 15200 LR: 0.000024 Total Loss: 0.0879 Runtime: 8.91 s/50 iters.\n",
      "==> Epoch: 30 Step: 15250 LR: 0.000024 Total Loss: 0.2038 Runtime: 8.56 s/50 iters.\n",
      "==> Epoch: 30 Step: 15300 LR: 0.000024 Total Loss: 0.0122 Runtime: 8.71 s/50 iters.\n",
      "==> Epoch: 30 Step: 15350 LR: 0.000024 Total Loss: 0.0052 Runtime: 8.57 s/50 iters.\n",
      "==> Epoch: 30 Step: 15400 LR: 0.000024 Total Loss: 0.0121 Runtime: 8.54 s/50 iters.\n",
      "==> Epoch: 30 Step: 15450 LR: 0.000024 Total Loss: 0.0039 Runtime: 8.74 s/50 iters.\n",
      "==> Epoch: 30 Step: 15500 LR: 0.000024 Total Loss: 0.0021 Runtime: 8.50 s/50 iters.\n",
      "==> Epoch: 30 Step: 15550 LR: 0.000024 Total Loss: 0.0077 Runtime: 8.94 s/50 iters.\n",
      "==> Epoch: 30 Step: 15600 LR: 0.000024 Total Loss: 0.0127 Runtime: 8.84 s/50 iters.\n",
      "==> Epoch: 30 Loss 0.045409 .\n",
      "==> Runtime: 52.34 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "My_model = trainer.train(my_extended_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
